{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33db4011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load starting\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "job_timestamp = datetime(2011, 1, 1, 0, 0, 0)\n",
    "print('Load starting')\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "#prefix_file_path = f'./transformed_data/{job_timestamp}'\n",
    "#dim_customer = spark.read.csv(f'{prefix_file_path}/dim_customer')\n",
    "#print(dim_customer.count(), len(dim_customer.columns))\n",
    "#dim_film = transformed_dfs['dim_film']\n",
    "#dim_store = transformed_dfs['dim_store']\n",
    "#dim_date = transformed_dfs['dim_date']\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c653565e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/06 17:10:00 INFO SparkContext: Running Spark version 3.5.0\n",
      "23/12/06 17:10:00 INFO SparkContext: OS info Linux, 6.2.0-37-generic, amd64\n",
      "23/12/06 17:10:00 INFO SparkContext: Java version 11.0.13\n",
      "23/12/06 17:10:00 INFO ResourceUtils: ==============================================================\n",
      "23/12/06 17:10:00 INFO ResourceUtils: No custom resources configured for spark.driver.\n",
      "23/12/06 17:10:00 INFO ResourceUtils: ==============================================================\n",
      "23/12/06 17:10:00 INFO SparkContext: Submitted application: Load\n",
      "23/12/06 17:10:00 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)\n",
      "23/12/06 17:10:00 INFO ResourceProfile: Limiting resource is cpu\n",
      "23/12/06 17:10:00 INFO ResourceProfileManager: Added ResourceProfile id: 0\n",
      "23/12/06 17:10:00 INFO SecurityManager: Changing view acls to: me\n",
      "23/12/06 17:10:00 INFO SecurityManager: Changing modify acls to: me\n",
      "23/12/06 17:10:00 INFO SecurityManager: Changing view acls groups to: \n",
      "23/12/06 17:10:00 INFO SecurityManager: Changing modify acls groups to: \n",
      "23/12/06 17:10:00 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: me; groups with view permissions: EMPTY; users with modify permissions: me; groups with modify permissions: EMPTY\n",
      "23/12/06 17:10:00 INFO Utils: Successfully started service 'sparkDriver' on port 43275.\n",
      "23/12/06 17:10:00 INFO SparkEnv: Registering MapOutputTracker\n",
      "23/12/06 17:10:00 INFO SparkEnv: Registering BlockManagerMaster\n",
      "23/12/06 17:10:00 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information\n",
      "23/12/06 17:10:00 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up\n",
      "23/12/06 17:10:00 INFO SparkEnv: Registering BlockManagerMasterHeartbeat\n",
      "23/12/06 17:10:00 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-99135b3a-b77a-4ea8-88c2-fe5f25aedf46\n",
      "23/12/06 17:10:00 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB\n",
      "23/12/06 17:10:00 INFO SparkEnv: Registering OutputCommitCoordinator\n",
      "23/12/06 17:10:00 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI\n",
      "23/12/06 17:10:00 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "23/12/06 17:10:00 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "23/12/06 17:10:00 INFO Utils: Successfully started service 'SparkUI' on port 4042.\n",
      "23/12/06 17:10:00 INFO SparkContext: Added JAR /home/me/spark/jars/postgresql-42.7.0.jar at spark://192.168.42.129:43275/jars/postgresql-42.7.0.jar with timestamp 1701853800236\n",
      "23/12/06 17:10:00 INFO Executor: Starting executor ID driver on host 192.168.42.129\n",
      "23/12/06 17:10:00 INFO Executor: OS info Linux, 6.2.0-37-generic, amd64\n",
      "23/12/06 17:10:00 INFO Executor: Java version 11.0.13\n",
      "23/12/06 17:10:00 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''\n",
      "23/12/06 17:10:00 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@4ff525ac for default.\n",
      "23/12/06 17:10:00 INFO Executor: Fetching spark://192.168.42.129:43275/jars/postgresql-42.7.0.jar with timestamp 1701853800236\n",
      "23/12/06 17:10:00 INFO TransportClientFactory: Successfully created connection to /192.168.42.129:43275 after 104 ms (0 ms spent in bootstraps)\n",
      "23/12/06 17:10:00 INFO Utils: Fetching spark://192.168.42.129:43275/jars/postgresql-42.7.0.jar to /tmp/spark-19a090b1-be7f-4e2c-801a-ddaffff528a7/userFiles-a5b6f57d-ddb6-47a4-b934-d8d20d1d007a/fetchFileTemp1093517516205803365.tmp\n",
      "23/12/06 17:10:00 INFO Executor: Adding file:/tmp/spark-19a090b1-be7f-4e2c-801a-ddaffff528a7/userFiles-a5b6f57d-ddb6-47a4-b934-d8d20d1d007a/postgresql-42.7.0.jar to class loader default\n",
      "23/12/06 17:10:00 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43857.\n",
      "23/12/06 17:10:00 INFO NettyBlockTransferService: Server created on 192.168.42.129:43857\n",
      "23/12/06 17:10:00 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\n",
      "23/12/06 17:10:00 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.42.129, 43857, None)\n",
      "23/12/06 17:10:00 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.42.129:43857 with 434.4 MiB RAM, BlockManagerId(driver, 192.168.42.129, 43857, None)\n",
      "23/12/06 17:10:00 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.42.129, 43857, None)\n",
      "23/12/06 17:10:00 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.42.129, 43857, None)\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder\\\n",
    ".config('spark.jars', '/home/me/spark/jars/postgresql-42.7.0.jar')\\\n",
    ".appName(\"Load\") \\\n",
    ".master(\"local[*]\") \\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f108cdac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def read_data(table_name):\n",
    "#     df = spark.read\\\n",
    "#     .format('jdbc')\\\n",
    "#     .option('url', 'jdbc:postgresql://localhost:5432/alabama')\\\n",
    "#     .option('driver', 'org.postgresql.Driver')\\\n",
    "#     .option('dbtable', table_name)\\\n",
    "#     .option('user', 'my_user')\\\n",
    "#     .option('password', 'my_user_1')\\\n",
    "#     .load()\n",
    "    \n",
    "#     return df\n",
    "\n",
    "# df = read_data('dim_store')\n",
    "# df.show()\n",
    "# df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfa3e52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df.write\\\n",
    "# .format(\"jdbc\")\\\n",
    "# .option(\"url\", 'jdbc:postgresql://localhost:5432/alabama')\\\n",
    "# .option(\"driver\", \"org.postgresql.Driver\")\\\n",
    "# .option(\"dbtable\", 'dim_store')\\\n",
    "# .option(\"user\", 'my_user')\\\n",
    "# .option(\"password\", 'my_user_1')\\\n",
    "# .option('mode', 'append')\\\n",
    "# .save()\n",
    "# #.option(\"numPartitions\", 2)\\\n",
    "# #.option('isolationLevel', 'SERIALIZABLE')\\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e902e5ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+--------+-----------+----+-------+\n",
      "|store_id|address|district|postal_code|city|country|\n",
      "+--------+-------+--------+-----------+----+-------+\n",
      "+--------+-------+--------+-----------+----+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/06 17:49:55 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\n",
      "23/12/06 17:49:55 INFO DAGScheduler: Got job 12 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/12/06 17:49:55 INFO DAGScheduler: Final stage: ResultStage 12 (showString at NativeMethodAccessorImpl.java:0)\n",
      "23/12/06 17:49:55 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/12/06 17:49:55 INFO DAGScheduler: Missing parents: List()\n",
      "23/12/06 17:49:55 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[50] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/12/06 17:49:55 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 15.3 KiB, free 434.4 MiB)\n",
      "23/12/06 17:49:55 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 434.4 MiB)\n",
      "23/12/06 17:49:55 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 192.168.42.129:43857 (size: 7.0 KiB, free: 434.4 MiB)\n",
      "23/12/06 17:49:55 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1580\n",
      "23/12/06 17:49:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[50] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/12/06 17:49:55 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks resource profile 0\n",
      "23/12/06 17:49:55 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 12) (192.168.42.129, executor driver, partition 0, PROCESS_LOCAL, 7643 bytes) \n",
      "23/12/06 17:49:55 INFO Executor: Running task 0.0 in stage 12.0 (TID 12)\n",
      "23/12/06 17:49:55 INFO JDBCRDD: closed connection\n",
      "23/12/06 17:49:55 INFO Executor: Finished task 0.0 in stage 12.0 (TID 12). 1409 bytes result sent to driver\n",
      "23/12/06 17:49:55 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 12) in 77 ms on 192.168.42.129 (executor driver) (1/1)\n",
      "23/12/06 17:49:55 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool \n",
      "23/12/06 17:49:55 INFO DAGScheduler: ResultStage 12 (showString at NativeMethodAccessorImpl.java:0) finished in 0.123 s\n",
      "23/12/06 17:49:55 INFO DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/12/06 17:49:55 INFO TaskSchedulerImpl: Killing all running tasks in stage 12: Stage finished\n",
      "23/12/06 17:49:55 INFO DAGScheduler: Job 12 finished: showString at NativeMethodAccessorImpl.java:0, took 0.135402 s\n",
      "23/12/06 18:10:00 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 192.168.42.129:43857 in memory (size: 7.0 KiB, free: 434.4 MiB)\n",
      "23/12/06 18:10:01 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 192.168.42.129:43857 in memory (size: 7.0 KiB, free: 434.4 MiB)\n"
     ]
    }
   ],
   "source": [
    "postgres_url = 'jdbc:postgresql://localhost:5432/alabama'\n",
    "properties = {\n",
    "    \"user\": \"my_user\",\n",
    "    \"password\": \"my_user_1\",\n",
    "    \"driver\": \"org.postgresql.Driver\",\n",
    "    \"isolationLevel\": \"SERIALIZABLE\"\n",
    "}\n",
    "df_ = spark.read.jdbc(url=postgres_url, table=\"dim_store\", properties=properties)\n",
    "df_.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5b2542ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/06 18:13:25 INFO SparkContext: Starting job: jdbc at NativeMethodAccessorImpl.java:0\n",
      "23/12/06 18:13:25 INFO DAGScheduler: Got job 16 (jdbc at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/12/06 18:13:25 INFO DAGScheduler: Final stage: ResultStage 16 (jdbc at NativeMethodAccessorImpl.java:0)\n",
      "23/12/06 18:13:25 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/12/06 18:13:25 INFO DAGScheduler: Missing parents: List()\n",
      "23/12/06 18:13:25 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[64] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/12/06 18:13:26 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 33.7 KiB, free 434.3 MiB)\n",
      "23/12/06 18:13:26 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 15.2 KiB, free 434.3 MiB)\n",
      "23/12/06 18:13:26 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 192.168.42.129:43857 (size: 15.2 KiB, free: 434.4 MiB)\n",
      "23/12/06 18:13:26 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1580\n",
      "23/12/06 18:13:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[64] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/12/06 18:13:26 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks resource profile 0\n",
      "23/12/06 18:13:26 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 16) (192.168.42.129, executor driver, partition 0, PROCESS_LOCAL, 7643 bytes) \n",
      "23/12/06 18:13:26 INFO Executor: Running task 0.0 in stage 16.0 (TID 16)\n",
      "23/12/06 18:13:26 INFO JDBCRDD: closed connection\n",
      "23/12/06 18:13:26 INFO Executor: Finished task 0.0 in stage 16.0 (TID 16). 1230 bytes result sent to driver\n",
      "23/12/06 18:13:26 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 16) in 80 ms on 192.168.42.129 (executor driver) (1/1)\n",
      "23/12/06 18:13:26 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool \n",
      "23/12/06 18:13:26 INFO DAGScheduler: ResultStage 16 (jdbc at NativeMethodAccessorImpl.java:0) finished in 0.188 s\n",
      "23/12/06 18:13:26 INFO DAGScheduler: Job 16 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/12/06 18:13:26 INFO TaskSchedulerImpl: Killing all running tasks in stage 16: Stage finished\n",
      "23/12/06 18:13:26 INFO DAGScheduler: Job 16 finished: jdbc at NativeMethodAccessorImpl.java:0, took 0.213373 s\n"
     ]
    }
   ],
   "source": [
    "postgres_url = 'jdbc:postgresql://localhost:5432/alabama'\n",
    "properties = {\n",
    "    \"user\": \"my_user\",\n",
    "    \"password\": \"my_user_1\",\n",
    "    \"driver\": \"org.postgresql.Driver\",\n",
    "    \"numPartitions\": '2', # equal to or lesser than the no. partitions of the DF\n",
    "    \"isolationLevel\": \"SERIALIZABLE\"\n",
    "}\n",
    "df.write.jdbc(url=postgres_url, table=\"dim_store\", mode=\"append\", properties=properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "fa986287",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_db(table):\n",
    "    \"\"\"\n",
    "    Returns a table as a dataframe. db: alabama db_vendor: posgresql\n",
    "    \"\"\"\n",
    "    postgres_url = 'jdbc:postgresql://localhost:5432/alabama'\n",
    "    properties = {\n",
    "        \"user\": \"my_user\",\n",
    "        \"password\": \"my_user_1\",\n",
    "        \"driver\": \"org.postgresql.Driver\",\n",
    "        \"isolationLevel\": \"SERIALIZABLE\"\n",
    "    }\n",
    "    \n",
    "    return spark.read.jdbc(url=postgres_url, table=table, properties=properties)\n",
    "\n",
    "def write_df(df, table, partitions):\n",
    "    \"\"\"\n",
    "    Write appends a dataframe as a table. db: alabama db_vendor: posgresql\n",
    "    \"\"\"\n",
    "    postgres_url = 'jdbc:postgresql://localhost:5432/alabama'\n",
    "    properties = {\n",
    "        \"user\": \"my_user\",\n",
    "        \"password\": \"my_user_1\",\n",
    "        \"driver\": \"org.postgresql.Driver\",\n",
    "        \"numPartitions\": str(partitions), # equal to or lesser than the no. partitions of the DF\n",
    "        \"isolationLevel\": \"SERIALIZABLE\"\n",
    "    }\n",
    "    df.write.jdbc(url=postgres_url, table=table, mode=\"append\", properties=properties)\n",
    "    \n",
    "def filter_load_dim_df(df, table, partitions, idx_col):\n",
    "    \"\"\"\n",
    "    Function for filtering out existing rows in the dimension tables before updating the data.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read table\n",
    "    print(f'Reading {table}')\n",
    "    existing_table = read_db(table)\n",
    "    \n",
    "    # Filter out existing ids\n",
    "    print(f'Filtering rows from {table}')\n",
    "    non_existing_rows = df.join(existing_table, [idx_col, idx_col], \"leftanti\")\n",
    "    #existing_ids = existing_table.select(idx_col).collect()\n",
    "    #print(existing_ids)\n",
    "    #non_existing_rows = df.filter(~df[idx_col].isin(existing_ids))\n",
    "    \n",
    "    # Load rows with ids not present in the database\n",
    "    print(f'Loading {table}')\n",
    "    write_df(non_existing_rows, table, partitions)\n",
    "    \n",
    "    print(f'Load for {table} done')\n",
    "    \n",
    "def load_fact_df(df, table, partitions):\n",
    "    print(f'Loading {table}')\n",
    "    write_df(df, table, partitions)\n",
    "    print(f'Load for {table} done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "32715b52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/06 19:54:51 INFO SparkContext: Starting job: collect at /tmp/ipykernel_17573/638528617.py:2\n",
      "23/12/06 19:54:51 INFO DAGScheduler: Got job 78 (collect at /tmp/ipykernel_17573/638528617.py:2) with 1 output partitions\n",
      "23/12/06 19:54:51 INFO DAGScheduler: Final stage: ResultStage 78 (collect at /tmp/ipykernel_17573/638528617.py:2)\n",
      "23/12/06 19:54:51 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/12/06 19:54:51 INFO DAGScheduler: Missing parents: List()\n",
      "23/12/06 19:54:51 INFO DAGScheduler: Submitting ResultStage 78 (MapPartitionsRDD[326] at collect at /tmp/ipykernel_17573/638528617.py:2), which has no missing parents\n",
      "23/12/06 19:54:51 INFO MemoryStore: Block broadcast_102 stored as values in memory (estimated size 10.8 KiB, free 434.4 MiB)\n",
      "23/12/06 19:54:51 INFO MemoryStore: Block broadcast_102_piece0 stored as bytes in memory (estimated size 5.6 KiB, free 434.4 MiB)\n",
      "23/12/06 19:54:51 INFO BlockManagerInfo: Added broadcast_102_piece0 in memory on 192.168.42.129:43857 (size: 5.6 KiB, free: 434.4 MiB)\n",
      "23/12/06 19:54:51 INFO SparkContext: Created broadcast 102 from broadcast at DAGScheduler.scala:1580\n",
      "23/12/06 19:54:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 78 (MapPartitionsRDD[326] at collect at /tmp/ipykernel_17573/638528617.py:2) (first 15 tasks are for partitions Vector(0))\n",
      "23/12/06 19:54:51 INFO TaskSchedulerImpl: Adding task set 78.0 with 1 tasks resource profile 0\n",
      "23/12/06 19:54:51 INFO TaskSetManager: Starting task 0.0 in stage 78.0 (TID 105) (192.168.42.129, executor driver, partition 0, PROCESS_LOCAL, 7643 bytes) \n",
      "23/12/06 19:54:51 INFO Executor: Running task 0.0 in stage 78.0 (TID 105)\n",
      "23/12/06 19:54:51 INFO BlockManagerInfo: Removed broadcast_100_piece0 on 192.168.42.129:43857 in memory (size: 5.6 KiB, free: 434.4 MiB)\n",
      "23/12/06 19:54:51 INFO BlockManagerInfo: Removed broadcast_101_piece0 on 192.168.42.129:43857 in memory (size: 5.6 KiB, free: 434.4 MiB)\n",
      "23/12/06 19:54:51 INFO JDBCRDD: closed connection\n",
      "23/12/06 19:54:51 INFO Executor: Finished task 0.0 in stage 78.0 (TID 105). 1512 bytes result sent to driver\n",
      "23/12/06 19:54:51 INFO TaskSetManager: Finished task 0.0 in stage 78.0 (TID 105) in 133 ms on 192.168.42.129 (executor driver) (1/1)\n",
      "23/12/06 19:54:51 INFO TaskSchedulerImpl: Removed TaskSet 78.0, whose tasks have all completed, from pool \n",
      "23/12/06 19:54:51 INFO DAGScheduler: ResultStage 78 (collect at /tmp/ipykernel_17573/638528617.py:2) finished in 0.270 s\n",
      "23/12/06 19:54:51 INFO DAGScheduler: Job 78 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/12/06 19:54:51 INFO TaskSchedulerImpl: Killing all running tasks in stage 78: Stage finished\n",
      "23/12/06 19:54:51 INFO DAGScheduler: Job 78 finished: collect at /tmp/ipykernel_17573/638528617.py:2, took 0.275666 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(store_id=2), Row(store_id=1)]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "existing_table = read_db('dim_store')\n",
    "existing_ids = existing_table.select('store_id').collect()\n",
    "list(existing_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "5982c272",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/06 19:58:32 INFO FileSourceStrategy: Pushed Filters: \n",
      "23/12/06 19:58:32 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "23/12/06 19:58:32 INFO FileSourceStrategy: Pushed Filters: IsNotNull(store_id)\n",
      "23/12/06 19:58:32 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(store_id#2485)\n",
      "23/12/06 19:58:32 INFO CodeGenerator: Code generated in 11.011761 ms\n",
      "23/12/06 19:58:32 INFO MemoryStore: Block broadcast_103 stored as values in memory (estimated size 200.0 KiB, free 434.2 MiB)\n",
      "23/12/06 19:58:32 INFO MemoryStore: Block broadcast_103_piece0 stored as bytes in memory (estimated size 34.5 KiB, free 434.2 MiB)\n",
      "23/12/06 19:58:32 INFO BlockManagerInfo: Added broadcast_103_piece0 in memory on 192.168.42.129:43857 (size: 34.5 KiB, free: 434.4 MiB)\n",
      "23/12/06 19:58:32 INFO SparkContext: Created broadcast 103 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264\n",
      "23/12/06 19:58:32 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "23/12/06 19:58:32 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264\n",
      "23/12/06 19:58:32 INFO DAGScheduler: Got job 79 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 2 output partitions\n",
      "23/12/06 19:58:32 INFO DAGScheduler: Final stage: ResultStage 79 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)\n",
      "23/12/06 19:58:32 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/12/06 19:58:32 INFO DAGScheduler: Missing parents: List()\n",
      "23/12/06 19:58:32 INFO DAGScheduler: Submitting ResultStage 79 (MapPartitionsRDD[330] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents\n",
      "23/12/06 19:58:32 INFO MemoryStore: Block broadcast_104 stored as values in memory (estimated size 15.1 KiB, free 434.1 MiB)\n",
      "23/12/06 19:58:32 INFO MemoryStore: Block broadcast_104_piece0 stored as bytes in memory (estimated size 7.5 KiB, free 434.1 MiB)\n",
      "23/12/06 19:58:32 INFO BlockManagerInfo: Added broadcast_104_piece0 in memory on 192.168.42.129:43857 (size: 7.5 KiB, free: 434.4 MiB)\n",
      "23/12/06 19:58:32 INFO SparkContext: Created broadcast 104 from broadcast at DAGScheduler.scala:1580\n",
      "23/12/06 19:58:32 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 79 (MapPartitionsRDD[330] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0, 1))\n",
      "23/12/06 19:58:32 INFO TaskSchedulerImpl: Adding task set 79.0 with 2 tasks resource profile 0\n",
      "23/12/06 19:58:32 INFO TaskSetManager: Starting task 0.0 in stage 79.0 (TID 106) (192.168.42.129, executor driver, partition 0, PROCESS_LOCAL, 8534 bytes) \n",
      "23/12/06 19:58:32 INFO TaskSetManager: Starting task 1.0 in stage 79.0 (TID 107) (192.168.42.129, executor driver, partition 1, PROCESS_LOCAL, 8534 bytes) \n",
      "23/12/06 19:58:32 INFO Executor: Running task 0.0 in stage 79.0 (TID 106)\n",
      "23/12/06 19:58:32 INFO CodeGenerator: Code generated in 9.839423 ms\n",
      "23/12/06 19:58:32 INFO Executor: Running task 1.0 in stage 79.0 (TID 107)\n",
      "23/12/06 19:58:32 INFO FileScanRDD: Reading File path: file:///home/me/folder_1/gitfolder/ETL-pyspark-airflow-postgres/dags/transformed_data/2011-01-01%2000:00:00/dim_store/part-00009-0282cfd6-2f0e-435b-8d47-65baf50ef872-c000.csv, range: 0-98, partition values: [empty row]\n",
      "23/12/06 19:58:32 INFO FileScanRDD: Reading File path: file:///home/me/folder_1/gitfolder/ETL-pyspark-airflow-postgres/dags/transformed_data/2011-01-01%2000:00:00/dim_store/part-00000-0282cfd6-2f0e-435b-8d47-65baf50ef872-c000.csv, range: 0-97, partition values: [empty row]\n",
      "23/12/06 19:58:32 INFO CodeGenerator: Code generated in 11.079171 ms\n",
      "23/12/06 19:58:33 INFO Executor: Finished task 0.0 in stage 79.0 (TID 106). 1647 bytes result sent to driver\n",
      "23/12/06 19:58:33 INFO TaskSetManager: Finished task 0.0 in stage 79.0 (TID 106) in 147 ms on 192.168.42.129 (executor driver) (1/2)\n",
      "23/12/06 19:58:33 INFO BlockManagerInfo: Removed broadcast_102_piece0 on 192.168.42.129:43857 in memory (size: 5.6 KiB, free: 434.4 MiB)\n",
      "23/12/06 19:58:33 INFO Executor: Finished task 1.0 in stage 79.0 (TID 107). 1647 bytes result sent to driver\n",
      "23/12/06 19:58:33 INFO TaskSetManager: Finished task 1.0 in stage 79.0 (TID 107) in 166 ms on 192.168.42.129 (executor driver) (2/2)\n",
      "23/12/06 19:58:33 INFO TaskSchedulerImpl: Removed TaskSet 79.0, whose tasks have all completed, from pool \n",
      "23/12/06 19:58:33 INFO DAGScheduler: ResultStage 79 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.188 s\n",
      "23/12/06 19:58:33 INFO DAGScheduler: Job 79 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/12/06 19:58:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 79: Stage finished\n",
      "23/12/06 19:58:33 INFO DAGScheduler: Job 79 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.194768 s\n",
      "23/12/06 19:58:33 INFO CodeGenerator: Code generated in 12.219451 ms\n",
      "23/12/06 19:58:33 INFO MemoryStore: Block broadcast_105 stored as values in memory (estimated size 1024.0 KiB, free 433.1 MiB)\n",
      "23/12/06 19:58:33 INFO MemoryStore: Block broadcast_105_piece0 stored as bytes in memory (estimated size 212.0 B, free 433.1 MiB)\n",
      "23/12/06 19:58:33 INFO BlockManagerInfo: Added broadcast_105_piece0 in memory on 192.168.42.129:43857 (size: 212.0 B, free: 434.4 MiB)\n",
      "23/12/06 19:58:33 INFO SparkContext: Created broadcast 105 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264\n",
      "23/12/06 19:58:33 INFO BlockManagerInfo: Removed broadcast_104_piece0 on 192.168.42.129:43857 in memory (size: 7.5 KiB, free: 434.4 MiB)\n",
      "23/12/06 19:58:33 INFO FileSourceStrategy: Pushed Filters: \n",
      "23/12/06 19:58:33 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "23/12/06 19:58:33 INFO CodeGenerator: Code generated in 20.004364 ms\n",
      "23/12/06 19:58:33 INFO MemoryStore: Block broadcast_106 stored as values in memory (estimated size 200.0 KiB, free 433.0 MiB)\n",
      "23/12/06 19:58:33 INFO MemoryStore: Block broadcast_106_piece0 stored as bytes in memory (estimated size 34.5 KiB, free 432.9 MiB)\n",
      "23/12/06 19:58:33 INFO BlockManagerInfo: Added broadcast_106_piece0 in memory on 192.168.42.129:43857 (size: 34.5 KiB, free: 434.3 MiB)\n",
      "23/12/06 19:58:33 INFO SparkContext: Created broadcast 106 from showString at <unknown>:0\n",
      "23/12/06 19:58:33 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "23/12/06 19:58:33 INFO SparkContext: Starting job: showString at <unknown>:0\n",
      "23/12/06 19:58:33 INFO DAGScheduler: Got job 80 (showString at <unknown>:0) with 1 output partitions\n",
      "23/12/06 19:58:33 INFO DAGScheduler: Final stage: ResultStage 80 (showString at <unknown>:0)\n",
      "23/12/06 19:58:33 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/12/06 19:58:33 INFO DAGScheduler: Missing parents: List()\n",
      "23/12/06 19:58:33 INFO DAGScheduler: Submitting ResultStage 80 (MapPartitionsRDD[334] at showString at <unknown>:0), which has no missing parents\n",
      "23/12/06 19:58:33 INFO MemoryStore: Block broadcast_107 stored as values in memory (estimated size 18.6 KiB, free 432.9 MiB)\n",
      "23/12/06 19:58:33 INFO MemoryStore: Block broadcast_107_piece0 stored as bytes in memory (estimated size 8.6 KiB, free 432.9 MiB)\n",
      "23/12/06 19:58:33 INFO BlockManagerInfo: Added broadcast_107_piece0 in memory on 192.168.42.129:43857 (size: 8.6 KiB, free: 434.3 MiB)\n",
      "23/12/06 19:58:33 INFO SparkContext: Created broadcast 107 from broadcast at DAGScheduler.scala:1580\n",
      "23/12/06 19:58:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 80 (MapPartitionsRDD[334] at showString at <unknown>:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/12/06 19:58:33 INFO TaskSchedulerImpl: Adding task set 80.0 with 1 tasks resource profile 0\n",
      "23/12/06 19:58:33 INFO TaskSetManager: Starting task 0.0 in stage 80.0 (TID 108) (192.168.42.129, executor driver, partition 0, PROCESS_LOCAL, 8534 bytes) \n",
      "23/12/06 19:58:33 INFO Executor: Running task 0.0 in stage 80.0 (TID 108)\n",
      "23/12/06 19:58:33 INFO CodeGenerator: Code generated in 24.689142 ms\n",
      "23/12/06 19:58:33 INFO FileScanRDD: Reading File path: file:///home/me/folder_1/gitfolder/ETL-pyspark-airflow-postgres/dags/transformed_data/2011-01-01%2000:00:00/dim_store/part-00009-0282cfd6-2f0e-435b-8d47-65baf50ef872-c000.csv, range: 0-98, partition values: [empty row]\n",
      "23/12/06 19:58:33 INFO Executor: Finished task 0.0 in stage 80.0 (TID 108). 1637 bytes result sent to driver\n",
      "23/12/06 19:58:33 INFO TaskSetManager: Finished task 0.0 in stage 80.0 (TID 108) in 88 ms on 192.168.42.129 (executor driver) (1/1)\n",
      "23/12/06 19:58:33 INFO TaskSchedulerImpl: Removed TaskSet 80.0, whose tasks have all completed, from pool \n",
      "23/12/06 19:58:33 INFO DAGScheduler: ResultStage 80 (showString at <unknown>:0) finished in 0.108 s\n",
      "23/12/06 19:58:33 INFO DAGScheduler: Job 80 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/12/06 19:58:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 80: Stage finished\n",
      "23/12/06 19:58:33 INFO DAGScheduler: Job 80 finished: showString at <unknown>:0, took 0.116205 s\n",
      "23/12/06 19:58:33 INFO SparkContext: Starting job: showString at <unknown>:0\n",
      "23/12/06 19:58:33 INFO DAGScheduler: Got job 81 (showString at <unknown>:0) with 1 output partitions\n",
      "23/12/06 19:58:33 INFO DAGScheduler: Final stage: ResultStage 81 (showString at <unknown>:0)\n",
      "23/12/06 19:58:33 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/12/06 19:58:33 INFO DAGScheduler: Missing parents: List()\n",
      "23/12/06 19:58:33 INFO DAGScheduler: Submitting ResultStage 81 (MapPartitionsRDD[334] at showString at <unknown>:0), which has no missing parents\n",
      "23/12/06 19:58:33 INFO MemoryStore: Block broadcast_108 stored as values in memory (estimated size 18.6 KiB, free 432.9 MiB)\n",
      "23/12/06 19:58:33 INFO MemoryStore: Block broadcast_108_piece0 stored as bytes in memory (estimated size 8.6 KiB, free 432.9 MiB)\n",
      "23/12/06 19:58:33 INFO BlockManagerInfo: Added broadcast_108_piece0 in memory on 192.168.42.129:43857 (size: 8.6 KiB, free: 434.3 MiB)\n",
      "23/12/06 19:58:33 INFO SparkContext: Created broadcast 108 from broadcast at DAGScheduler.scala:1580\n",
      "23/12/06 19:58:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 81 (MapPartitionsRDD[334] at showString at <unknown>:0) (first 15 tasks are for partitions Vector(1))\n",
      "23/12/06 19:58:33 INFO TaskSchedulerImpl: Adding task set 81.0 with 1 tasks resource profile 0\n",
      "23/12/06 19:58:33 INFO TaskSetManager: Starting task 0.0 in stage 81.0 (TID 109) (192.168.42.129, executor driver, partition 1, PROCESS_LOCAL, 8534 bytes) \n",
      "23/12/06 19:58:33 INFO Executor: Running task 0.0 in stage 81.0 (TID 109)\n",
      "23/12/06 19:58:33 INFO FileScanRDD: Reading File path: file:///home/me/folder_1/gitfolder/ETL-pyspark-airflow-postgres/dags/transformed_data/2011-01-01%2000:00:00/dim_store/part-00000-0282cfd6-2f0e-435b-8d47-65baf50ef872-c000.csv, range: 0-97, partition values: [empty row]\n",
      "23/12/06 19:58:33 INFO Executor: Finished task 0.0 in stage 81.0 (TID 109). 1594 bytes result sent to driver\n",
      "23/12/06 19:58:33 INFO TaskSetManager: Finished task 0.0 in stage 81.0 (TID 109) in 18 ms on 192.168.42.129 (executor driver) (1/1)\n",
      "23/12/06 19:58:33 INFO TaskSchedulerImpl: Removed TaskSet 81.0, whose tasks have all completed, from pool \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+-------+--------+-----------+----+-------+\n",
      "|store_id|store_id|address|district|postal_code|city|country|\n",
      "+--------+--------+-------+--------+-----------+----+-------+\n",
      "+--------+--------+-------+--------+-----------+----+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/06 19:58:33 INFO DAGScheduler: ResultStage 81 (showString at <unknown>:0) finished in 0.032 s\n",
      "23/12/06 19:58:33 INFO DAGScheduler: Job 81 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/12/06 19:58:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 81: Stage finished\n",
      "23/12/06 19:58:33 INFO DAGScheduler: Job 81 finished: showString at <unknown>:0, took 0.038160 s\n",
      "23/12/06 20:10:01 INFO BlockManagerInfo: Removed broadcast_107_piece0 on 192.168.42.129:43857 in memory (size: 8.6 KiB, free: 434.3 MiB)\n",
      "23/12/06 20:10:01 INFO BlockManagerInfo: Removed broadcast_108_piece0 on 192.168.42.129:43857 in memory (size: 8.6 KiB, free: 434.3 MiB)\n",
      "23/12/06 20:10:01 INFO BlockManagerInfo: Removed broadcast_106_piece0 on 192.168.42.129:43857 in memory (size: 34.5 KiB, free: 434.4 MiB)\n",
      "23/12/06 20:10:01 INFO BlockManagerInfo: Removed broadcast_105_piece0 on 192.168.42.129:43857 in memory (size: 212.0 B, free: 434.4 MiB)\n",
      "23/12/06 20:10:01 INFO BlockManagerInfo: Removed broadcast_103_piece0 on 192.168.42.129:43857 in memory (size: 34.5 KiB, free: 434.4 MiB)\n"
     ]
    }
   ],
   "source": [
    "# This is what I want\n",
    "dim_store.join(dim_store, ['store_id', 'store_id'], \"leftanti\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "8fa99c03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/06 19:46:20 INFO FileSourceStrategy: Pushed Filters: Not(In(store_id, [1,2]))\n",
      "23/12/06 19:46:20 INFO FileSourceStrategy: Post-Scan Filters: NOT store_id#1671 IN (1,2)\n",
      "23/12/06 19:46:20 INFO CodeGenerator: Code generated in 25.890567 ms\n",
      "23/12/06 19:46:20 INFO MemoryStore: Block broadcast_87 stored as values in memory (estimated size 200.0 KiB, free 434.2 MiB)\n",
      "23/12/06 19:46:20 INFO MemoryStore: Block broadcast_87_piece0 stored as bytes in memory (estimated size 34.5 KiB, free 434.2 MiB)\n",
      "23/12/06 19:46:20 INFO BlockManagerInfo: Added broadcast_87_piece0 in memory on 192.168.42.129:43857 (size: 34.5 KiB, free: 434.4 MiB)\n",
      "23/12/06 19:46:20 INFO SparkContext: Created broadcast 87 from showString at <unknown>:0\n",
      "23/12/06 19:46:20 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "23/12/06 19:46:20 INFO SparkContext: Starting job: showString at <unknown>:0\n",
      "23/12/06 19:46:20 INFO DAGScheduler: Got job 64 (showString at <unknown>:0) with 1 output partitions\n",
      "23/12/06 19:46:20 INFO DAGScheduler: Final stage: ResultStage 64 (showString at <unknown>:0)\n",
      "23/12/06 19:46:20 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/12/06 19:46:20 INFO DAGScheduler: Missing parents: List()\n",
      "23/12/06 19:46:20 INFO DAGScheduler: Submitting ResultStage 64 (MapPartitionsRDD[287] at showString at <unknown>:0), which has no missing parents\n",
      "23/12/06 19:46:20 INFO MemoryStore: Block broadcast_88 stored as values in memory (estimated size 18.5 KiB, free 434.1 MiB)\n",
      "23/12/06 19:46:20 INFO MemoryStore: Block broadcast_88_piece0 stored as bytes in memory (estimated size 8.4 KiB, free 434.1 MiB)\n",
      "23/12/06 19:46:20 INFO BlockManagerInfo: Added broadcast_88_piece0 in memory on 192.168.42.129:43857 (size: 8.4 KiB, free: 434.4 MiB)\n",
      "23/12/06 19:46:20 INFO SparkContext: Created broadcast 88 from broadcast at DAGScheduler.scala:1580\n",
      "23/12/06 19:46:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 64 (MapPartitionsRDD[287] at showString at <unknown>:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/12/06 19:46:20 INFO TaskSchedulerImpl: Adding task set 64.0 with 1 tasks resource profile 0\n",
      "23/12/06 19:46:20 INFO TaskSetManager: Starting task 0.0 in stage 64.0 (TID 91) (192.168.42.129, executor driver, partition 0, PROCESS_LOCAL, 8534 bytes) \n",
      "23/12/06 19:46:20 INFO Executor: Running task 0.0 in stage 64.0 (TID 91)\n",
      "23/12/06 19:46:20 INFO CodeGenerator: Code generated in 27.69417 ms\n",
      "23/12/06 19:46:20 INFO FileScanRDD: Reading File path: file:///home/me/folder_1/gitfolder/ETL-pyspark-airflow-postgres/dags/transformed_data/2011-01-01%2000:00:00/dim_store/part-00009-0282cfd6-2f0e-435b-8d47-65baf50ef872-c000.csv, range: 0-98, partition values: [empty row]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+--------+-----------+----+-------+\n",
      "|store_id|address|district|postal_code|city|country|\n",
      "+--------+-------+--------+-----------+----+-------+\n",
      "+--------+-------+--------+-----------+----+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/06 19:46:20 INFO CodeGenerator: Code generated in 15.242928 ms\n",
      "23/12/06 19:46:20 INFO Executor: Finished task 0.0 in stage 64.0 (TID 91). 1551 bytes result sent to driver\n",
      "23/12/06 19:46:20 INFO BlockManagerInfo: Removed broadcast_86_piece0 on 192.168.42.129:43857 in memory (size: 5.6 KiB, free: 434.4 MiB)\n",
      "23/12/06 19:46:20 INFO TaskSetManager: Finished task 0.0 in stage 64.0 (TID 91) in 124 ms on 192.168.42.129 (executor driver) (1/1)\n",
      "23/12/06 19:46:20 INFO TaskSchedulerImpl: Removed TaskSet 64.0, whose tasks have all completed, from pool \n",
      "23/12/06 19:46:20 INFO DAGScheduler: ResultStage 64 (showString at <unknown>:0) finished in 0.145 s\n",
      "23/12/06 19:46:20 INFO DAGScheduler: Job 64 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/12/06 19:46:20 INFO TaskSchedulerImpl: Killing all running tasks in stage 64: Stage finished\n",
      "23/12/06 19:46:20 INFO DAGScheduler: Job 64 finished: showString at <unknown>:0, took 0.156040 s\n",
      "23/12/06 19:46:20 INFO SparkContext: Starting job: showString at <unknown>:0\n",
      "23/12/06 19:46:20 INFO DAGScheduler: Got job 65 (showString at <unknown>:0) with 1 output partitions\n",
      "23/12/06 19:46:20 INFO DAGScheduler: Final stage: ResultStage 65 (showString at <unknown>:0)\n",
      "23/12/06 19:46:20 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/12/06 19:46:20 INFO DAGScheduler: Missing parents: List()\n",
      "23/12/06 19:46:20 INFO DAGScheduler: Submitting ResultStage 65 (MapPartitionsRDD[287] at showString at <unknown>:0), which has no missing parents\n",
      "23/12/06 19:46:20 INFO MemoryStore: Block broadcast_89 stored as values in memory (estimated size 18.5 KiB, free 434.1 MiB)\n",
      "23/12/06 19:46:20 INFO MemoryStore: Block broadcast_89_piece0 stored as bytes in memory (estimated size 8.4 KiB, free 434.1 MiB)\n",
      "23/12/06 19:46:20 INFO BlockManagerInfo: Added broadcast_89_piece0 in memory on 192.168.42.129:43857 (size: 8.4 KiB, free: 434.3 MiB)\n",
      "23/12/06 19:46:20 INFO SparkContext: Created broadcast 89 from broadcast at DAGScheduler.scala:1580\n",
      "23/12/06 19:46:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 65 (MapPartitionsRDD[287] at showString at <unknown>:0) (first 15 tasks are for partitions Vector(1))\n",
      "23/12/06 19:46:20 INFO TaskSchedulerImpl: Adding task set 65.0 with 1 tasks resource profile 0\n",
      "23/12/06 19:46:20 INFO TaskSetManager: Starting task 0.0 in stage 65.0 (TID 92) (192.168.42.129, executor driver, partition 1, PROCESS_LOCAL, 8534 bytes) \n",
      "23/12/06 19:46:20 INFO Executor: Running task 0.0 in stage 65.0 (TID 92)\n",
      "23/12/06 19:46:20 INFO FileScanRDD: Reading File path: file:///home/me/folder_1/gitfolder/ETL-pyspark-airflow-postgres/dags/transformed_data/2011-01-01%2000:00:00/dim_store/part-00000-0282cfd6-2f0e-435b-8d47-65baf50ef872-c000.csv, range: 0-97, partition values: [empty row]\n",
      "23/12/06 19:46:20 INFO Executor: Finished task 0.0 in stage 65.0 (TID 92). 1508 bytes result sent to driver\n",
      "23/12/06 19:46:20 INFO TaskSetManager: Finished task 0.0 in stage 65.0 (TID 92) in 42 ms on 192.168.42.129 (executor driver) (1/1)\n",
      "23/12/06 19:46:20 INFO TaskSchedulerImpl: Removed TaskSet 65.0, whose tasks have all completed, from pool \n",
      "23/12/06 19:46:20 INFO DAGScheduler: ResultStage 65 (showString at <unknown>:0) finished in 0.056 s\n",
      "23/12/06 19:46:20 INFO DAGScheduler: Job 65 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/12/06 19:46:20 INFO TaskSchedulerImpl: Killing all running tasks in stage 65: Stage finished\n",
      "23/12/06 19:46:20 INFO DAGScheduler: Job 65 finished: showString at <unknown>:0, took 0.072993 s\n"
     ]
    }
   ],
   "source": [
    "dim_store.filter(~dim_store['store_id'].isin([1,2])).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f87c2cf3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/06 19:15:55 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.\n",
      "23/12/06 19:15:55 INFO InMemoryFileIndex: It took 9 ms to list leaf files for 1 paths.\n",
      "23/12/06 19:15:55 INFO InMemoryFileIndex: It took 3 ms to list leaf files for 1 paths.\n",
      "23/12/06 19:15:55 INFO InMemoryFileIndex: It took 12 ms to list leaf files for 1 paths.\n",
      "23/12/06 19:15:55 INFO InMemoryFileIndex: It took 8 ms to list leaf files for 1 paths.\n"
     ]
    }
   ],
   "source": [
    "prefix_file_path = f'./transformed_data/{job_timestamp}'\n",
    "\n",
    "dim_customer = spark.read.csv(f'{prefix_file_path}/dim_customer',\n",
    "                              header=True,\n",
    "                              schema='customer_id int, first_name string, last_name string, active int, address string, district string, city string, country string')\n",
    "\n",
    "dim_film = spark.read.csv(path=f'{prefix_file_path}/dim_film',\n",
    "                          header=True,\n",
    "                          schema='film_id int, title string, description string, release_year int, rental_duration int, rental_rate float, length int, replacement_cost float, rating string, language string, category string')\n",
    "\n",
    "dim_store = spark.read.csv(path=f'{prefix_file_path}/dim_store',\n",
    "                           header=True,\n",
    "                           schema='store_id int, address string, district string, postal_code int, city string, country string')\n",
    "\n",
    "dim_date = spark.read.csv(path=f'{prefix_file_path}/dim_date',\n",
    "                          header=True,\n",
    "                          schema='date timestamp, datekey int, year int, month int, day int, quarter int, dayofweek int')\n",
    "\n",
    "fact_sale = spark.read.csv(path=f'{prefix_file_path}/fact_sales',\n",
    "                           header=True,\n",
    "                           schema='payment_id int, customer_id int, film_id int, store_id int, payment_date timestamp, sale_amount float, rental_date timestamp, return_date timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "4040ba98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dim_customer\n",
      "Filtering rows from dim_customer\n",
      "Loading dim_customer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/06 20:15:34 INFO FileSourceStrategy: Pushed Filters: \n",
      "23/12/06 20:15:34 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "23/12/06 20:15:34 INFO MemoryStore: Block broadcast_109 stored as values in memory (estimated size 200.0 KiB, free 434.2 MiB)\n",
      "23/12/06 20:15:34 INFO MemoryStore: Block broadcast_109_piece0 stored as bytes in memory (estimated size 34.5 KiB, free 434.2 MiB)\n",
      "23/12/06 20:15:34 INFO BlockManagerInfo: Added broadcast_109_piece0 in memory on 192.168.42.129:43857 (size: 34.5 KiB, free: 434.4 MiB)\n",
      "23/12/06 20:15:34 INFO SparkContext: Created broadcast 109 from jdbc at <unknown>:0\n",
      "23/12/06 20:15:34 INFO FileSourceScanExec: Planning scan with bin packing, max size: 5248096 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "23/12/06 20:15:34 INFO DAGScheduler: Registering RDD 338 (jdbc at <unknown>:0) as input to shuffle 0\n",
      "23/12/06 20:15:34 INFO DAGScheduler: Got map stage job 82 (jdbc at <unknown>:0) with 5 output partitions\n",
      "23/12/06 20:15:34 INFO DAGScheduler: Final stage: ShuffleMapStage 82 (jdbc at <unknown>:0)\n",
      "23/12/06 20:15:34 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/12/06 20:15:34 INFO DAGScheduler: Missing parents: List()\n",
      "23/12/06 20:15:34 INFO DAGScheduler: Submitting ShuffleMapStage 82 (MapPartitionsRDD[338] at jdbc at <unknown>:0), which has no missing parents\n",
      "23/12/06 20:15:34 INFO MemoryStore: Block broadcast_110 stored as values in memory (estimated size 15.4 KiB, free 434.2 MiB)\n",
      "23/12/06 20:15:34 INFO MemoryStore: Block broadcast_110_piece0 stored as bytes in memory (estimated size 7.7 KiB, free 434.1 MiB)\n",
      "23/12/06 20:15:34 INFO BlockManagerInfo: Added broadcast_110_piece0 in memory on 192.168.42.129:43857 (size: 7.7 KiB, free: 434.4 MiB)\n",
      "23/12/06 20:15:34 INFO SparkContext: Created broadcast 110 from broadcast at DAGScheduler.scala:1580\n",
      "23/12/06 20:15:34 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 82 (MapPartitionsRDD[338] at jdbc at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))\n",
      "23/12/06 20:15:34 INFO TaskSchedulerImpl: Adding task set 82.0 with 5 tasks resource profile 0\n",
      "23/12/06 20:15:34 INFO DAGScheduler: Registering RDD 340 (jdbc at <unknown>:0) as input to shuffle 1\n",
      "23/12/06 20:15:34 INFO DAGScheduler: Got map stage job 83 (jdbc at <unknown>:0) with 1 output partitions\n",
      "23/12/06 20:15:34 INFO DAGScheduler: Final stage: ShuffleMapStage 83 (jdbc at <unknown>:0)\n",
      "23/12/06 20:15:34 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/12/06 20:15:34 INFO DAGScheduler: Missing parents: List()\n",
      "23/12/06 20:15:34 INFO TaskSetManager: Starting task 0.0 in stage 82.0 (TID 110) (192.168.42.129, executor driver, partition 0, PROCESS_LOCAL, 8760 bytes) \n",
      "23/12/06 20:15:34 INFO DAGScheduler: Submitting ShuffleMapStage 83 (MapPartitionsRDD[340] at jdbc at <unknown>:0), which has no missing parents\n",
      "23/12/06 20:15:34 INFO TaskSetManager: Starting task 1.0 in stage 82.0 (TID 111) (192.168.42.129, executor driver, partition 1, PROCESS_LOCAL, 8760 bytes) \n",
      "23/12/06 20:15:34 INFO TaskSetManager: Starting task 2.0 in stage 82.0 (TID 112) (192.168.42.129, executor driver, partition 2, PROCESS_LOCAL, 8760 bytes) \n",
      "23/12/06 20:15:34 INFO TaskSetManager: Starting task 3.0 in stage 82.0 (TID 113) (192.168.42.129, executor driver, partition 3, PROCESS_LOCAL, 8760 bytes) \n",
      "23/12/06 20:15:34 INFO TaskSetManager: Starting task 4.0 in stage 82.0 (TID 114) (192.168.42.129, executor driver, partition 4, PROCESS_LOCAL, 8760 bytes) \n",
      "23/12/06 20:15:34 INFO Executor: Running task 0.0 in stage 82.0 (TID 110)\n",
      "23/12/06 20:15:34 INFO Executor: Running task 1.0 in stage 82.0 (TID 111)\n",
      "23/12/06 20:15:34 INFO Executor: Running task 2.0 in stage 82.0 (TID 112)\n",
      "23/12/06 20:15:34 INFO Executor: Running task 3.0 in stage 82.0 (TID 113)\n",
      "23/12/06 20:15:34 INFO Executor: Running task 4.0 in stage 82.0 (TID 114)\n",
      "23/12/06 20:15:35 INFO MemoryStore: Block broadcast_111 stored as values in memory (estimated size 13.9 KiB, free 434.1 MiB)\n",
      "23/12/06 20:15:35 INFO MemoryStore: Block broadcast_111_piece0 stored as bytes in memory (estimated size 7.3 KiB, free 434.1 MiB)\n",
      "23/12/06 20:15:35 INFO BlockManagerInfo: Added broadcast_111_piece0 in memory on 192.168.42.129:43857 (size: 7.3 KiB, free: 434.4 MiB)\n",
      "23/12/06 20:15:35 INFO SparkContext: Created broadcast 111 from broadcast at DAGScheduler.scala:1580\n",
      "23/12/06 20:15:35 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 83 (MapPartitionsRDD[340] at jdbc at <unknown>:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/12/06 20:15:35 INFO TaskSchedulerImpl: Adding task set 83.0 with 1 tasks resource profile 0\n",
      "23/12/06 20:15:35 INFO TaskSetManager: Starting task 0.0 in stage 83.0 (TID 115) (192.168.42.129, executor driver, partition 0, PROCESS_LOCAL, 7632 bytes) \n",
      "23/12/06 20:15:35 INFO Executor: Running task 0.0 in stage 83.0 (TID 115)\n",
      "23/12/06 20:15:35 INFO CodeGenerator: Code generated in 28.115002 ms\n",
      "23/12/06 20:15:35 INFO FileScanRDD: Reading File path: file:///home/me/folder_1/gitfolder/ETL-pyspark-airflow-postgres/dags/transformed_data/2011-01-01%2000:00:00/dim_customer/part-00008-ce97ca24-aeb9-49ed-a7df-2d36e5e5affc-c000.csv, range: 0-4205, partition values: [empty row]\n",
      "23/12/06 20:15:35 INFO FileScanRDD: Reading File path: file:///home/me/folder_1/gitfolder/ETL-pyspark-airflow-postgres/dags/transformed_data/2011-01-01%2000:00:00/dim_customer/part-00005-ce97ca24-aeb9-49ed-a7df-2d36e5e5affc-c000.csv, range: 0-4182, partition values: [empty row]\n",
      "23/12/06 20:15:35 INFO FileScanRDD: Reading File path: file:///home/me/folder_1/gitfolder/ETL-pyspark-airflow-postgres/dags/transformed_data/2011-01-01%2000:00:00/dim_customer/part-00006-ce97ca24-aeb9-49ed-a7df-2d36e5e5affc-c000.csv, range: 0-4254, partition values: [empty row]\n",
      "23/12/06 20:15:35 INFO FileScanRDD: Reading File path: file:///home/me/folder_1/gitfolder/ETL-pyspark-airflow-postgres/dags/transformed_data/2011-01-01%2000:00:00/dim_customer/part-00009-ce97ca24-aeb9-49ed-a7df-2d36e5e5affc-c000.csv, range: 0-4120, partition values: [empty row]\n",
      "23/12/06 20:15:35 INFO FileScanRDD: Reading File path: file:///home/me/folder_1/gitfolder/ETL-pyspark-airflow-postgres/dags/transformed_data/2011-01-01%2000:00:00/dim_customer/part-00001-ce97ca24-aeb9-49ed-a7df-2d36e5e5affc-c000.csv, range: 0-4144, partition values: [empty row]\n",
      "23/12/06 20:15:35 INFO FileScanRDD: Reading File path: file:///home/me/folder_1/gitfolder/ETL-pyspark-airflow-postgres/dags/transformed_data/2011-01-01%2000:00:00/dim_customer/part-00007-ce97ca24-aeb9-49ed-a7df-2d36e5e5affc-c000.csv, range: 0-4101, partition values: [empty row]\n",
      "23/12/06 20:15:35 INFO FileScanRDD: Reading File path: file:///home/me/folder_1/gitfolder/ETL-pyspark-airflow-postgres/dags/transformed_data/2011-01-01%2000:00:00/dim_customer/part-00004-ce97ca24-aeb9-49ed-a7df-2d36e5e5affc-c000.csv, range: 0-4232, partition values: [empty row]\n",
      "23/12/06 20:15:35 INFO FileScanRDD: Reading File path: file:///home/me/folder_1/gitfolder/ETL-pyspark-airflow-postgres/dags/transformed_data/2011-01-01%2000:00:00/dim_customer/part-00003-ce97ca24-aeb9-49ed-a7df-2d36e5e5affc-c000.csv, range: 0-4188, partition values: [empty row]\n",
      "23/12/06 20:15:35 INFO FileScanRDD: Reading File path: file:///home/me/folder_1/gitfolder/ETL-pyspark-airflow-postgres/dags/transformed_data/2011-01-01%2000:00:00/dim_customer/part-00000-ce97ca24-aeb9-49ed-a7df-2d36e5e5affc-c000.csv, range: 0-4143, partition values: [empty row]\n",
      "23/12/06 20:15:35 INFO FileScanRDD: Reading File path: file:///home/me/folder_1/gitfolder/ETL-pyspark-airflow-postgres/dags/transformed_data/2011-01-01%2000:00:00/dim_customer/part-00002-ce97ca24-aeb9-49ed-a7df-2d36e5e5affc-c000.csv, range: 0-4161, partition values: [empty row]\n",
      "23/12/06 20:15:35 INFO JDBCRDD: closed connection:>                 (0 + 1) / 1]\n",
      "23/12/06 20:15:35 INFO Executor: Finished task 4.0 in stage 82.0 (TID 114). 2005 bytes result sent to driver\n",
      "23/12/06 20:15:35 INFO Executor: Finished task 0.0 in stage 82.0 (TID 110). 2005 bytes result sent to driver\n",
      "23/12/06 20:15:35 INFO TaskSetManager: Finished task 0.0 in stage 82.0 (TID 110) in 966 ms on 192.168.42.129 (executor driver) (1/5)\n",
      "23/12/06 20:15:35 INFO TaskSetManager: Finished task 4.0 in stage 82.0 (TID 114) in 967 ms on 192.168.42.129 (executor driver) (2/5)\n",
      "23/12/06 20:15:35 INFO Executor: Finished task 3.0 in stage 82.0 (TID 113). 1962 bytes result sent to driver\n",
      "23/12/06 20:15:36 INFO Executor: Finished task 1.0 in stage 82.0 (TID 111). 2005 bytes result sent to driver\n",
      "23/12/06 20:15:36 INFO TaskSetManager: Finished task 3.0 in stage 82.0 (TID 113) in 1123 ms on 192.168.42.129 (executor driver) (3/5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/06 20:15:36 INFO TaskSetManager: Finished task 1.0 in stage 82.0 (TID 111) in 1186 ms on 192.168.42.129 (executor driver) (4/5)\n",
      "23/12/06 20:15:36 INFO Executor: Finished task 2.0 in stage 82.0 (TID 112). 1962 bytes result sent to driver\n",
      "23/12/06 20:15:36 INFO TaskSetManager: Finished task 2.0 in stage 82.0 (TID 112) in 1203 ms on 192.168.42.129 (executor driver) (5/5)\n",
      "23/12/06 20:15:36 INFO TaskSchedulerImpl: Removed TaskSet 82.0, whose tasks have all completed, from pool \n",
      "23/12/06 20:15:36 INFO DAGScheduler: ShuffleMapStage 82 (jdbc at <unknown>:0) finished in 1.290 s\n",
      "23/12/06 20:15:36 INFO DAGScheduler: looking for newly runnable stages\n",
      "23/12/06 20:15:36 INFO DAGScheduler: running: Set(ShuffleMapStage 83)\n",
      "23/12/06 20:15:36 INFO DAGScheduler: waiting: Set()\n",
      "23/12/06 20:15:36 INFO DAGScheduler: failed: Set()\n",
      "23/12/06 20:15:36 INFO Executor: Finished task 0.0 in stage 83.0 (TID 115). 1991 bytes result sent to driver\n",
      "23/12/06 20:15:36 INFO TaskSetManager: Finished task 0.0 in stage 83.0 (TID 115) in 1129 ms on 192.168.42.129 (executor driver) (1/1)\n",
      "23/12/06 20:15:36 INFO TaskSchedulerImpl: Removed TaskSet 83.0, whose tasks have all completed, from pool \n",
      "23/12/06 20:15:36 INFO DAGScheduler: ShuffleMapStage 83 (jdbc at <unknown>:0) finished in 1.244 s\n",
      "23/12/06 20:15:36 INFO DAGScheduler: looking for newly runnable stages\n",
      "23/12/06 20:15:36 INFO DAGScheduler: running: Set()\n",
      "23/12/06 20:15:36 INFO DAGScheduler: waiting: Set()\n",
      "23/12/06 20:15:36 INFO DAGScheduler: failed: Set()\n",
      "23/12/06 20:15:36 INFO ShufflePartitionsUtil: For shuffle(1), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "23/12/06 20:15:36 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264\n",
      "23/12/06 20:15:36 INFO DAGScheduler: Got job 84 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions\n",
      "23/12/06 20:15:36 INFO DAGScheduler: Final stage: ResultStage 85 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)\n",
      "23/12/06 20:15:36 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 84)\n",
      "23/12/06 20:15:36 INFO DAGScheduler: Missing parents: List()\n",
      "23/12/06 20:15:36 INFO DAGScheduler: Submitting ResultStage 85 (MapPartitionsRDD[342] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents\n",
      "23/12/06 20:15:36 INFO MemoryStore: Block broadcast_112 stored as values in memory (estimated size 8.2 KiB, free 434.1 MiB)\n",
      "23/12/06 20:15:36 INFO MemoryStore: Block broadcast_112_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 434.1 MiB)\n",
      "23/12/06 20:15:36 INFO BlockManagerInfo: Added broadcast_112_piece0 in memory on 192.168.42.129:43857 (size: 4.2 KiB, free: 434.3 MiB)\n",
      "23/12/06 20:15:36 INFO SparkContext: Created broadcast 112 from broadcast at DAGScheduler.scala:1580\n",
      "23/12/06 20:15:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 85 (MapPartitionsRDD[342] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))\n",
      "23/12/06 20:15:36 INFO TaskSchedulerImpl: Adding task set 85.0 with 1 tasks resource profile 0\n",
      "23/12/06 20:15:36 INFO TaskSetManager: Starting task 0.0 in stage 85.0 (TID 116) (192.168.42.129, executor driver, partition 0, NODE_LOCAL, 7816 bytes) \n",
      "23/12/06 20:15:36 INFO Executor: Running task 0.0 in stage 85.0 (TID 116)\n",
      "23/12/06 20:15:36 INFO ShuffleBlockFetcherIterator: Getting 1 (14.7 KiB) non-empty blocks including 1 (14.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "23/12/06 20:15:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 38 ms\n",
      "23/12/06 20:15:36 INFO Executor: Finished task 0.0 in stage 85.0 (TID 116). 8107 bytes result sent to driver\n",
      "23/12/06 20:15:36 INFO TaskSetManager: Finished task 0.0 in stage 85.0 (TID 116) in 167 ms on 192.168.42.129 (executor driver) (1/1)\n",
      "23/12/06 20:15:36 INFO TaskSchedulerImpl: Removed TaskSet 85.0, whose tasks have all completed, from pool \n",
      "23/12/06 20:15:36 INFO DAGScheduler: ResultStage 85 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.194 s\n",
      "23/12/06 20:15:36 INFO DAGScheduler: Job 84 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/12/06 20:15:36 INFO TaskSchedulerImpl: Killing all running tasks in stage 85: Stage finished\n",
      "23/12/06 20:15:36 INFO DAGScheduler: Job 84 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.211124 s\n",
      "23/12/06 20:15:36 INFO CodeGenerator: Code generated in 11.443552 ms            \n",
      "23/12/06 20:15:36 INFO MemoryStore: Block broadcast_113 stored as values in memory (estimated size 1028.7 KiB, free 433.1 MiB)\n",
      "23/12/06 20:15:36 INFO MemoryStore: Block broadcast_113_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 433.1 MiB)\n",
      "23/12/06 20:15:36 INFO BlockManagerInfo: Added broadcast_113_piece0 in memory on 192.168.42.129:43857 (size: 6.7 KiB, free: 434.3 MiB)\n",
      "23/12/06 20:15:36 INFO SparkContext: Created broadcast 113 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264\n",
      "23/12/06 20:15:36 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "23/12/06 20:15:36 INFO CodeGenerator: Code generated in 22.95609 ms\n",
      "23/12/06 20:15:36 INFO SparkContext: Starting job: jdbc at <unknown>:0\n",
      "23/12/06 20:15:36 INFO DAGScheduler: Got job 85 (jdbc at <unknown>:0) with 1 output partitions\n",
      "23/12/06 20:15:36 INFO DAGScheduler: Final stage: ResultStage 87 (jdbc at <unknown>:0)\n",
      "23/12/06 20:15:36 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 86)\n",
      "23/12/06 20:15:36 INFO DAGScheduler: Missing parents: List()\n",
      "23/12/06 20:15:36 INFO DAGScheduler: Submitting ResultStage 87 (MapPartitionsRDD[347] at jdbc at <unknown>:0), which has no missing parents\n",
      "23/12/06 20:15:36 INFO MemoryStore: Block broadcast_114 stored as values in memory (estimated size 52.9 KiB, free 433.1 MiB)\n",
      "23/12/06 20:15:36 INFO MemoryStore: Block broadcast_114_piece0 stored as bytes in memory (estimated size 24.3 KiB, free 433.0 MiB)\n",
      "23/12/06 20:15:36 INFO BlockManagerInfo: Added broadcast_114_piece0 in memory on 192.168.42.129:43857 (size: 24.3 KiB, free: 434.3 MiB)\n",
      "23/12/06 20:15:36 INFO SparkContext: Created broadcast 114 from broadcast at DAGScheduler.scala:1580\n",
      "23/12/06 20:15:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 87 (MapPartitionsRDD[347] at jdbc at <unknown>:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/12/06 20:15:36 INFO TaskSchedulerImpl: Adding task set 87.0 with 1 tasks resource profile 0\n",
      "23/12/06 20:15:36 INFO TaskSetManager: Starting task 0.0 in stage 87.0 (TID 117) (192.168.42.129, executor driver, partition 0, NODE_LOCAL, 7813 bytes) \n",
      "23/12/06 20:15:36 INFO Executor: Running task 0.0 in stage 87.0 (TID 117)\n",
      "23/12/06 20:15:36 INFO ShuffleBlockFetcherIterator: Getting 5 (98.6 KiB) non-empty blocks including 5 (98.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "23/12/06 20:15:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms\n",
      "23/12/06 20:15:36 INFO CodeGenerator: Code generated in 21.986219 ms\n",
      "23/12/06 20:15:36 INFO CodeGenerator: Code generated in 28.816916 ms\n",
      "23/12/06 20:15:37 INFO Executor: Finished task 0.0 in stage 87.0 (TID 117). 5769 bytes result sent to driver\n",
      "23/12/06 20:15:37 INFO TaskSetManager: Finished task 0.0 in stage 87.0 (TID 117) in 135 ms on 192.168.42.129 (executor driver) (1/1)\n",
      "23/12/06 20:15:37 INFO TaskSchedulerImpl: Removed TaskSet 87.0, whose tasks have all completed, from pool \n",
      "23/12/06 20:15:37 INFO DAGScheduler: ResultStage 87 (jdbc at <unknown>:0) finished in 0.327 s\n",
      "23/12/06 20:15:37 INFO DAGScheduler: Job 85 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/12/06 20:15:37 INFO TaskSchedulerImpl: Killing all running tasks in stage 87: Stage finished\n",
      "23/12/06 20:15:37 INFO DAGScheduler: Job 85 finished: jdbc at <unknown>:0, took 0.334204 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load for dim_customer done\n"
     ]
    }
   ],
   "source": [
    "filter_load_dim_df(dim_customer, 'dim_customer', 4, 'customer_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "4407a6d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dim_film\n",
      "Filtering rows from dim_film\n",
      "Loading dim_film\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/06 20:15:51 INFO FileSourceStrategy: Pushed Filters: \n",
      "23/12/06 20:15:51 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "23/12/06 20:15:51 INFO MemoryStore: Block broadcast_115 stored as values in memory (estimated size 200.0 KiB, free 432.8 MiB)\n",
      "23/12/06 20:15:51 INFO BlockManagerInfo: Removed broadcast_112_piece0 on 192.168.42.129:43857 in memory (size: 4.2 KiB, free: 434.3 MiB)\n",
      "23/12/06 20:15:51 INFO MemoryStore: Block broadcast_115_piece0 stored as bytes in memory (estimated size 34.5 KiB, free 432.8 MiB)\n",
      "23/12/06 20:15:51 INFO BlockManagerInfo: Added broadcast_115_piece0 in memory on 192.168.42.129:43857 (size: 34.5 KiB, free: 434.3 MiB)\n",
      "23/12/06 20:15:51 INFO SparkContext: Created broadcast 115 from jdbc at <unknown>:0\n",
      "23/12/06 20:15:51 INFO FileSourceScanExec: Planning scan with bin packing, max size: 5262394 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "23/12/06 20:15:51 INFO BlockManagerInfo: Removed broadcast_114_piece0 on 192.168.42.129:43857 in memory (size: 24.3 KiB, free: 434.3 MiB)\n",
      "23/12/06 20:15:51 INFO DAGScheduler: Registering RDD 351 (jdbc at <unknown>:0) as input to shuffle 2\n",
      "23/12/06 20:15:51 INFO DAGScheduler: Got map stage job 86 (jdbc at <unknown>:0) with 5 output partitions\n",
      "23/12/06 20:15:51 INFO DAGScheduler: Final stage: ShuffleMapStage 88 (jdbc at <unknown>:0)\n",
      "23/12/06 20:15:51 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/12/06 20:15:51 INFO DAGScheduler: Missing parents: List()\n",
      "23/12/06 20:15:51 INFO DAGScheduler: Submitting ShuffleMapStage 88 (MapPartitionsRDD[351] at jdbc at <unknown>:0), which has no missing parents\n",
      "23/12/06 20:15:51 INFO MemoryStore: Block broadcast_116 stored as values in memory (estimated size 16.1 KiB, free 432.9 MiB)\n",
      "23/12/06 20:15:51 INFO MemoryStore: Block broadcast_116_piece0 stored as bytes in memory (estimated size 8.0 KiB, free 432.9 MiB)\n",
      "23/12/06 20:15:51 INFO BlockManagerInfo: Added broadcast_116_piece0 in memory on 192.168.42.129:43857 (size: 8.0 KiB, free: 434.3 MiB)\n",
      "23/12/06 20:15:51 INFO SparkContext: Created broadcast 116 from broadcast at DAGScheduler.scala:1580\n",
      "23/12/06 20:15:51 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 88 (MapPartitionsRDD[351] at jdbc at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))\n",
      "23/12/06 20:15:51 INFO TaskSchedulerImpl: Adding task set 88.0 with 5 tasks resource profile 0\n",
      "23/12/06 20:15:51 INFO DAGScheduler: Registering RDD 353 (jdbc at <unknown>:0) as input to shuffle 3\n",
      "23/12/06 20:15:51 INFO DAGScheduler: Got map stage job 87 (jdbc at <unknown>:0) with 1 output partitions\n",
      "23/12/06 20:15:51 INFO DAGScheduler: Final stage: ShuffleMapStage 89 (jdbc at <unknown>:0)\n",
      "23/12/06 20:15:51 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/12/06 20:15:51 INFO DAGScheduler: Missing parents: List()\n",
      "23/12/06 20:15:51 INFO DAGScheduler: Submitting ShuffleMapStage 89 (MapPartitionsRDD[353] at jdbc at <unknown>:0), which has no missing parents\n",
      "23/12/06 20:15:51 INFO TaskSetManager: Starting task 0.0 in stage 88.0 (TID 118) (192.168.42.129, executor driver, partition 0, PROCESS_LOCAL, 8752 bytes) \n",
      "23/12/06 20:15:51 INFO TaskSetManager: Starting task 1.0 in stage 88.0 (TID 119) (192.168.42.129, executor driver, partition 1, PROCESS_LOCAL, 8752 bytes) \n",
      "23/12/06 20:15:51 INFO TaskSetManager: Starting task 2.0 in stage 88.0 (TID 120) (192.168.42.129, executor driver, partition 2, PROCESS_LOCAL, 8752 bytes) \n",
      "23/12/06 20:15:51 INFO TaskSetManager: Starting task 3.0 in stage 88.0 (TID 121) (192.168.42.129, executor driver, partition 3, PROCESS_LOCAL, 8752 bytes) \n",
      "23/12/06 20:15:51 INFO TaskSetManager: Starting task 4.0 in stage 88.0 (TID 122) (192.168.42.129, executor driver, partition 4, PROCESS_LOCAL, 8752 bytes) \n",
      "23/12/06 20:15:51 INFO Executor: Running task 3.0 in stage 88.0 (TID 121)\n",
      "23/12/06 20:15:51 INFO Executor: Running task 1.0 in stage 88.0 (TID 119)\n",
      "23/12/06 20:15:51 INFO Executor: Running task 0.0 in stage 88.0 (TID 118)\n",
      "23/12/06 20:15:51 INFO Executor: Running task 2.0 in stage 88.0 (TID 120)\n",
      "23/12/06 20:15:51 INFO Executor: Running task 4.0 in stage 88.0 (TID 122)\n",
      "23/12/06 20:15:51 INFO FileScanRDD: Reading File path: file:///home/me/folder_1/gitfolder/ETL-pyspark-airflow-postgres/dags/transformed_data/2011-01-01%2000:00:00/dim_film/part-00004-cea97e7a-244e-4f09-800e-a640398e7f80-c000.csv, range: 0-15602, partition values: [empty row]\n",
      "23/12/06 20:15:51 INFO MemoryStore: Block broadcast_117 stored as values in memory (estimated size 14.0 KiB, free 432.9 MiB)\n",
      "23/12/06 20:15:51 INFO MemoryStore: Block broadcast_117_piece0 stored as bytes in memory (estimated size 7.4 KiB, free 432.8 MiB)\n",
      "23/12/06 20:15:51 INFO FileScanRDD: Reading File path: file:///home/me/folder_1/gitfolder/ETL-pyspark-airflow-postgres/dags/transformed_data/2011-01-01%2000:00:00/dim_film/part-00009-cea97e7a-244e-4f09-800e-a640398e7f80-c000.csv, range: 0-15685, partition values: [empty row]\n",
      "23/12/06 20:15:51 INFO FileScanRDD: Reading File path: file:///home/me/folder_1/gitfolder/ETL-pyspark-airflow-postgres/dags/transformed_data/2011-01-01%2000:00:00/dim_film/part-00006-cea97e7a-244e-4f09-800e-a640398e7f80-c000.csv, range: 0-15362, partition values: [empty row]\n",
      "23/12/06 20:15:51 INFO BlockManagerInfo: Added broadcast_117_piece0 in memory on 192.168.42.129:43857 (size: 7.4 KiB, free: 434.3 MiB)\n",
      "23/12/06 20:15:51 INFO FileScanRDD: Reading File path: file:///home/me/folder_1/gitfolder/ETL-pyspark-airflow-postgres/dags/transformed_data/2011-01-01%2000:00:00/dim_film/part-00002-cea97e7a-244e-4f09-800e-a640398e7f80-c000.csv, range: 0-15697, partition values: [empty row]\n",
      "23/12/06 20:15:51 INFO SparkContext: Created broadcast 117 from broadcast at DAGScheduler.scala:1580\n",
      "23/12/06 20:15:51 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 89 (MapPartitionsRDD[353] at jdbc at <unknown>:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/12/06 20:15:51 INFO TaskSchedulerImpl: Adding task set 89.0 with 1 tasks resource profile 0\n",
      "23/12/06 20:15:51 INFO TaskSetManager: Starting task 0.0 in stage 89.0 (TID 123) (192.168.42.129, executor driver, partition 0, PROCESS_LOCAL, 7632 bytes) \n",
      "23/12/06 20:15:51 INFO FileScanRDD: Reading File path: file:///home/me/folder_1/gitfolder/ETL-pyspark-airflow-postgres/dags/transformed_data/2011-01-01%2000:00:00/dim_film/part-00003-cea97e7a-244e-4f09-800e-a640398e7f80-c000.csv, range: 0-15852, partition values: [empty row]\n",
      "23/12/06 20:15:51 INFO Executor: Running task 0.0 in stage 89.0 (TID 123)\n",
      "23/12/06 20:15:51 INFO FileScanRDD: Reading File path: file:///home/me/folder_1/gitfolder/ETL-pyspark-airflow-postgres/dags/transformed_data/2011-01-01%2000:00:00/dim_film/part-00008-cea97e7a-244e-4f09-800e-a640398e7f80-c000.csv, range: 0-15519, partition values: [empty row]\n",
      "23/12/06 20:15:51 INFO FileScanRDD: Reading File path: file:///home/me/folder_1/gitfolder/ETL-pyspark-airflow-postgres/dags/transformed_data/2011-01-01%2000:00:00/dim_film/part-00000-cea97e7a-244e-4f09-800e-a640398e7f80-c000.csv, range: 0-15641, partition values: [empty row]\n",
      "23/12/06 20:15:51 INFO FileScanRDD: Reading File path: file:///home/me/folder_1/gitfolder/ETL-pyspark-airflow-postgres/dags/transformed_data/2011-01-01%2000:00:00/dim_film/part-00007-cea97e7a-244e-4f09-800e-a640398e7f80-c000.csv, range: 0-15258, partition values: [empty row]\n",
      "23/12/06 20:15:51 INFO FileScanRDD: Reading File path: file:///home/me/folder_1/gitfolder/ETL-pyspark-airflow-postgres/dags/transformed_data/2011-01-01%2000:00:00/dim_film/part-00005-cea97e7a-244e-4f09-800e-a640398e7f80-c000.csv, range: 0-15690, partition values: [empty row]\n",
      "23/12/06 20:15:51 INFO FileScanRDD: Reading File path: file:///home/me/folder_1/gitfolder/ETL-pyspark-airflow-postgres/dags/transformed_data/2011-01-01%2000:00:00/dim_film/part-00001-cea97e7a-244e-4f09-800e-a640398e7f80-c000.csv, range: 0-15813, partition values: [empty row]\n",
      "23/12/06 20:15:51 INFO JDBCRDD: closed connection\n",
      "23/12/06 20:15:51 INFO BlockManagerInfo: Removed broadcast_109_piece0 on 192.168.42.129:43857 in memory (size: 34.5 KiB, free: 434.3 MiB)\n",
      "23/12/06 20:15:52 INFO BlockManagerInfo: Removed broadcast_110_piece0 on 192.168.42.129:43857 in memory (size: 7.7 KiB, free: 434.3 MiB)\n",
      "23/12/06 20:15:52 INFO BlockManagerInfo: Removed broadcast_111_piece0 on 192.168.42.129:43857 in memory (size: 7.3 KiB, free: 434.3 MiB)\n",
      "23/12/06 20:15:52 INFO Executor: Finished task 3.0 in stage 88.0 (TID 121). 2005 bytes result sent to driver\n",
      "23/12/06 20:15:52 INFO TaskSetManager: Finished task 3.0 in stage 88.0 (TID 121) in 757 ms on 192.168.42.129 (executor driver) (1/5)\n",
      "23/12/06 20:15:52 INFO Executor: Finished task 2.0 in stage 88.0 (TID 120). 1962 bytes result sent to driver\n",
      "23/12/06 20:15:52 INFO TaskSetManager: Finished task 2.0 in stage 88.0 (TID 120) in 775 ms on 192.168.42.129 (executor driver) (2/5)\n",
      "23/12/06 20:15:52 INFO Executor: Finished task 4.0 in stage 88.0 (TID 122). 1962 bytes result sent to driver\n",
      "23/12/06 20:15:52 INFO TaskSetManager: Finished task 4.0 in stage 88.0 (TID 122) in 791 ms on 192.168.42.129 (executor driver) (3/5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/06 20:15:52 INFO BlockManagerInfo: Removed broadcast_113_piece0 on 192.168.42.129:43857 in memory (size: 6.7 KiB, free: 434.4 MiB)\n",
      "23/12/06 20:15:52 INFO Executor: Finished task 0.0 in stage 88.0 (TID 118). 1962 bytes result sent to driver\n",
      "23/12/06 20:15:52 INFO Executor: Finished task 1.0 in stage 88.0 (TID 119). 1962 bytes result sent to driver\n",
      "23/12/06 20:15:52 INFO TaskSetManager: Finished task 0.0 in stage 88.0 (TID 118) in 961 ms on 192.168.42.129 (executor driver) (4/5)\n",
      "23/12/06 20:15:52 INFO TaskSetManager: Finished task 1.0 in stage 88.0 (TID 119) in 959 ms on 192.168.42.129 (executor driver) (5/5)\n",
      "23/12/06 20:15:52 INFO TaskSchedulerImpl: Removed TaskSet 88.0, whose tasks have all completed, from pool \n",
      "23/12/06 20:15:52 INFO DAGScheduler: ShuffleMapStage 88 (jdbc at <unknown>:0) finished in 1.012 s\n",
      "23/12/06 20:15:52 INFO DAGScheduler: looking for newly runnable stages\n",
      "23/12/06 20:15:52 INFO DAGScheduler: running: Set(ShuffleMapStage 89)\n",
      "23/12/06 20:15:52 INFO DAGScheduler: waiting: Set()\n",
      "23/12/06 20:15:52 INFO DAGScheduler: failed: Set()\n",
      "23/12/06 20:15:52 INFO Executor: Finished task 0.0 in stage 89.0 (TID 123). 1991 bytes result sent to driver\n",
      "23/12/06 20:15:52 INFO TaskSetManager: Finished task 0.0 in stage 89.0 (TID 123) in 886 ms on 192.168.42.129 (executor driver) (1/1)\n",
      "23/12/06 20:15:52 INFO TaskSchedulerImpl: Removed TaskSet 89.0, whose tasks have all completed, from pool \n",
      "23/12/06 20:15:52 INFO DAGScheduler: ShuffleMapStage 89 (jdbc at <unknown>:0) finished in 0.984 s\n",
      "23/12/06 20:15:52 INFO DAGScheduler: looking for newly runnable stages\n",
      "23/12/06 20:15:52 INFO DAGScheduler: running: Set()\n",
      "23/12/06 20:15:52 INFO DAGScheduler: waiting: Set()\n",
      "23/12/06 20:15:52 INFO DAGScheduler: failed: Set()\n",
      "23/12/06 20:15:52 INFO ShufflePartitionsUtil: For shuffle(3), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "23/12/06 20:15:52 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264\n",
      "23/12/06 20:15:52 INFO DAGScheduler: Got job 88 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions\n",
      "23/12/06 20:15:52 INFO DAGScheduler: Final stage: ResultStage 91 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)\n",
      "23/12/06 20:15:52 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 90)\n",
      "23/12/06 20:15:52 INFO DAGScheduler: Missing parents: List()\n",
      "23/12/06 20:15:52 INFO DAGScheduler: Submitting ResultStage 91 (MapPartitionsRDD[355] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents\n",
      "23/12/06 20:15:52 INFO MemoryStore: Block broadcast_118 stored as values in memory (estimated size 8.2 KiB, free 434.1 MiB)\n",
      "23/12/06 20:15:52 INFO MemoryStore: Block broadcast_118_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 434.1 MiB)\n",
      "23/12/06 20:15:52 INFO BlockManagerInfo: Added broadcast_118_piece0 in memory on 192.168.42.129:43857 (size: 4.2 KiB, free: 434.3 MiB)\n",
      "23/12/06 20:15:52 INFO SparkContext: Created broadcast 118 from broadcast at DAGScheduler.scala:1580\n",
      "23/12/06 20:15:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 91 (MapPartitionsRDD[355] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))\n",
      "23/12/06 20:15:52 INFO TaskSchedulerImpl: Adding task set 91.0 with 1 tasks resource profile 0\n",
      "23/12/06 20:15:52 INFO TaskSetManager: Starting task 0.0 in stage 91.0 (TID 124) (192.168.42.129, executor driver, partition 0, NODE_LOCAL, 7816 bytes) \n",
      "23/12/06 20:15:52 INFO Executor: Running task 0.0 in stage 91.0 (TID 124)\n",
      "23/12/06 20:15:52 INFO ShuffleBlockFetcherIterator: Getting 1 (18.7 KiB) non-empty blocks including 1 (18.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "23/12/06 20:15:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms\n",
      "23/12/06 20:15:52 INFO Executor: Finished task 0.0 in stage 91.0 (TID 124). 10087 bytes result sent to driver\n",
      "23/12/06 20:15:52 INFO TaskSetManager: Finished task 0.0 in stage 91.0 (TID 124) in 19 ms on 192.168.42.129 (executor driver) (1/1)\n",
      "23/12/06 20:15:52 INFO TaskSchedulerImpl: Removed TaskSet 91.0, whose tasks have all completed, from pool \n",
      "23/12/06 20:15:52 INFO DAGScheduler: ResultStage 91 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.030 s\n",
      "23/12/06 20:15:52 INFO DAGScheduler: Job 88 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/12/06 20:15:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 91: Stage finished\n",
      "23/12/06 20:15:52 INFO DAGScheduler: Job 88 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.038940 s\n",
      "23/12/06 20:15:52 INFO MemoryStore: Block broadcast_119 stored as values in memory (estimated size 1031.8 KiB, free 433.1 MiB)\n",
      "23/12/06 20:15:52 INFO MemoryStore: Block broadcast_119_piece0 stored as bytes in memory (estimated size 10.8 KiB, free 433.1 MiB)\n",
      "23/12/06 20:15:52 INFO BlockManagerInfo: Added broadcast_119_piece0 in memory on 192.168.42.129:43857 (size: 10.8 KiB, free: 434.3 MiB)\n",
      "23/12/06 20:15:52 INFO SparkContext: Created broadcast 119 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264\n",
      "23/12/06 20:15:52 INFO ShufflePartitionsUtil: For shuffle(2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "23/12/06 20:15:52 INFO BlockManagerInfo: Removed broadcast_118_piece0 on 192.168.42.129:43857 in memory (size: 4.2 KiB, free: 434.3 MiB)\n",
      "23/12/06 20:15:52 INFO CodeGenerator: Code generated in 76.481291 ms\n",
      "23/12/06 20:15:52 INFO SparkContext: Starting job: jdbc at <unknown>:0\n",
      "23/12/06 20:15:52 INFO DAGScheduler: Got job 89 (jdbc at <unknown>:0) with 1 output partitions\n",
      "23/12/06 20:15:52 INFO DAGScheduler: Final stage: ResultStage 93 (jdbc at <unknown>:0)\n",
      "23/12/06 20:15:52 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 92)\n",
      "23/12/06 20:15:52 INFO DAGScheduler: Missing parents: List()\n",
      "23/12/06 20:15:52 INFO DAGScheduler: Submitting ResultStage 93 (MapPartitionsRDD[360] at jdbc at <unknown>:0), which has no missing parents\n",
      "23/12/06 20:15:52 INFO MemoryStore: Block broadcast_120 stored as values in memory (estimated size 55.3 KiB, free 433.1 MiB)\n",
      "23/12/06 20:15:52 INFO MemoryStore: Block broadcast_120_piece0 stored as bytes in memory (estimated size 25.0 KiB, free 433.0 MiB)\n",
      "23/12/06 20:15:52 INFO BlockManagerInfo: Added broadcast_120_piece0 in memory on 192.168.42.129:43857 (size: 25.0 KiB, free: 434.3 MiB)\n",
      "23/12/06 20:15:52 INFO SparkContext: Created broadcast 120 from broadcast at DAGScheduler.scala:1580\n",
      "23/12/06 20:15:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 93 (MapPartitionsRDD[360] at jdbc at <unknown>:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/12/06 20:15:52 INFO TaskSchedulerImpl: Adding task set 93.0 with 1 tasks resource profile 0\n",
      "23/12/06 20:15:52 INFO TaskSetManager: Starting task 0.0 in stage 93.0 (TID 125) (192.168.42.129, executor driver, partition 0, NODE_LOCAL, 7813 bytes) \n",
      "23/12/06 20:15:52 INFO Executor: Running task 0.0 in stage 93.0 (TID 125)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load for dim_film done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/06 20:15:52 INFO ShuffleBlockFetcherIterator: Getting 5 (230.2 KiB) non-empty blocks including 5 (230.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "23/12/06 20:15:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms\n",
      "23/12/06 20:15:52 INFO CodeGenerator: Code generated in 18.288422 ms\n",
      "23/12/06 20:15:52 INFO CodeGenerator: Code generated in 27.85811 ms\n",
      "23/12/06 20:15:52 INFO Executor: Finished task 0.0 in stage 93.0 (TID 125). 5769 bytes result sent to driver\n",
      "23/12/06 20:15:52 INFO TaskSetManager: Finished task 0.0 in stage 93.0 (TID 125) in 117 ms on 192.168.42.129 (executor driver) (1/1)\n",
      "23/12/06 20:15:52 INFO TaskSchedulerImpl: Removed TaskSet 93.0, whose tasks have all completed, from pool \n",
      "23/12/06 20:15:52 INFO DAGScheduler: ResultStage 93 (jdbc at <unknown>:0) finished in 0.257 s\n",
      "23/12/06 20:15:52 INFO DAGScheduler: Job 89 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/12/06 20:15:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 93: Stage finished\n",
      "23/12/06 20:15:52 INFO DAGScheduler: Job 89 finished: jdbc at <unknown>:0, took 0.267183 s\n"
     ]
    }
   ],
   "source": [
    "filter_load_dim_df(dim_film, 'dim_film', 4, 'film_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "da2ee3a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dim_store\n",
      "Filtering rows from dim_store\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/06 19:49:18 INFO SparkContext: Starting job: collect at /tmp/ipykernel_17573/1681207761.py:40\n",
      "23/12/06 19:49:18 INFO DAGScheduler: Got job 68 (collect at /tmp/ipykernel_17573/1681207761.py:40) with 1 output partitions\n",
      "23/12/06 19:49:18 INFO DAGScheduler: Final stage: ResultStage 68 (collect at /tmp/ipykernel_17573/1681207761.py:40)\n",
      "23/12/06 19:49:18 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/12/06 19:49:18 INFO DAGScheduler: Missing parents: List()\n",
      "23/12/06 19:49:18 INFO DAGScheduler: Submitting ResultStage 68 (MapPartitionsRDD[296] at collect at /tmp/ipykernel_17573/1681207761.py:40), which has no missing parents\n",
      "23/12/06 19:49:18 INFO MemoryStore: Block broadcast_92 stored as values in memory (estimated size 10.8 KiB, free 434.4 MiB)\n",
      "23/12/06 19:49:18 INFO MemoryStore: Block broadcast_92_piece0 stored as bytes in memory (estimated size 5.6 KiB, free 434.4 MiB)\n",
      "23/12/06 19:49:18 INFO BlockManagerInfo: Added broadcast_92_piece0 in memory on 192.168.42.129:43857 (size: 5.6 KiB, free: 434.4 MiB)\n",
      "23/12/06 19:49:18 INFO BlockManagerInfo: Removed broadcast_91_piece0 on 192.168.42.129:43857 in memory (size: 5.6 KiB, free: 434.4 MiB)\n",
      "23/12/06 19:49:18 INFO SparkContext: Created broadcast 92 from broadcast at DAGScheduler.scala:1580\n",
      "23/12/06 19:49:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 68 (MapPartitionsRDD[296] at collect at /tmp/ipykernel_17573/1681207761.py:40) (first 15 tasks are for partitions Vector(0))\n",
      "23/12/06 19:49:18 INFO TaskSchedulerImpl: Adding task set 68.0 with 1 tasks resource profile 0\n",
      "23/12/06 19:49:18 INFO TaskSetManager: Starting task 0.0 in stage 68.0 (TID 95) (192.168.42.129, executor driver, partition 0, PROCESS_LOCAL, 7643 bytes) \n",
      "23/12/06 19:49:18 INFO Executor: Running task 0.0 in stage 68.0 (TID 95)\n",
      "23/12/06 19:49:18 INFO BlockManagerInfo: Removed broadcast_90_piece0 on 192.168.42.129:43857 in memory (size: 5.6 KiB, free: 434.4 MiB)\n",
      "23/12/06 19:49:18 INFO JDBCRDD: closed connection\n",
      "23/12/06 19:49:18 INFO Executor: Finished task 0.0 in stage 68.0 (TID 95). 1512 bytes result sent to driver\n",
      "23/12/06 19:49:18 INFO TaskSetManager: Finished task 0.0 in stage 68.0 (TID 95) in 116 ms on 192.168.42.129 (executor driver) (1/1)\n",
      "23/12/06 19:49:18 INFO TaskSchedulerImpl: Removed TaskSet 68.0, whose tasks have all completed, from pool \n",
      "23/12/06 19:49:18 INFO DAGScheduler: ResultStage 68 (collect at /tmp/ipykernel_17573/1681207761.py:40) finished in 0.254 s\n",
      "23/12/06 19:49:18 INFO DAGScheduler: Job 68 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/12/06 19:49:18 INFO TaskSchedulerImpl: Killing all running tasks in stage 68: Stage finished\n",
      "23/12/06 19:49:18 INFO DAGScheduler: Job 68 finished: collect at /tmp/ipykernel_17573/1681207761.py:40, took 0.261012 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(store_id=2), Row(store_id=1)]\n"
     ]
    },
    {
     "ename": "SparkRuntimeException",
     "evalue": "[UNSUPPORTED_FEATURE.LITERAL_TYPE] The feature is not supported: Literal for '[2]' of class java.util.ArrayList.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSparkRuntimeException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[139], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m filter_load_dim_df(dim_store, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdim_store\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstore_id\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[138], line 42\u001b[0m, in \u001b[0;36mfilter_load_dim_df\u001b[0;34m(df, table, partitions, idx_col)\u001b[0m\n\u001b[1;32m     40\u001b[0m existing_ids \u001b[38;5;241m=\u001b[39m existing_table\u001b[38;5;241m.\u001b[39mselect(idx_col)\u001b[38;5;241m.\u001b[39mcollect()\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(existing_ids)\n\u001b[0;32m---> 42\u001b[0m non_existing_rows \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mfilter(\u001b[38;5;241m~\u001b[39mdf[idx_col]\u001b[38;5;241m.\u001b[39misin(existing_ids))\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Load rows with ids not present in the database\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtable\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pyspark/sql/column.py:959\u001b[0m, in \u001b[0;36mColumn.isin\u001b[0;34m(self, *cols)\u001b[0m\n\u001b[1;32m    955\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(cols) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(cols[\u001b[38;5;241m0\u001b[39m], (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mset\u001b[39m)):\n\u001b[1;32m    956\u001b[0m     cols \u001b[38;5;241m=\u001b[39m cast(Tuple, cols[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    957\u001b[0m cols \u001b[38;5;241m=\u001b[39m cast(\n\u001b[1;32m    958\u001b[0m     Tuple,\n\u001b[0;32m--> 959\u001b[0m     [c\u001b[38;5;241m.\u001b[39m_jc \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(c, Column) \u001b[38;5;28;01melse\u001b[39;00m _create_column_from_literal(c) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m cols],\n\u001b[1;32m    960\u001b[0m )\n\u001b[1;32m    961\u001b[0m sc \u001b[38;5;241m=\u001b[39m get_active_spark_context()\n\u001b[1;32m    962\u001b[0m jc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jc, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124misin\u001b[39m\u001b[38;5;124m\"\u001b[39m)(_to_seq(sc, cols))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pyspark/sql/column.py:959\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    955\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(cols) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(cols[\u001b[38;5;241m0\u001b[39m], (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mset\u001b[39m)):\n\u001b[1;32m    956\u001b[0m     cols \u001b[38;5;241m=\u001b[39m cast(Tuple, cols[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    957\u001b[0m cols \u001b[38;5;241m=\u001b[39m cast(\n\u001b[1;32m    958\u001b[0m     Tuple,\n\u001b[0;32m--> 959\u001b[0m     [c\u001b[38;5;241m.\u001b[39m_jc \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(c, Column) \u001b[38;5;28;01melse\u001b[39;00m _create_column_from_literal(c) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m cols],\n\u001b[1;32m    960\u001b[0m )\n\u001b[1;32m    961\u001b[0m sc \u001b[38;5;241m=\u001b[39m get_active_spark_context()\n\u001b[1;32m    962\u001b[0m jc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jc, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124misin\u001b[39m\u001b[38;5;124m\"\u001b[39m)(_to_seq(sc, cols))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pyspark/sql/column.py:51\u001b[0m, in \u001b[0;36m_create_column_from_literal\u001b[0;34m(literal)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_create_column_from_literal\u001b[39m(literal: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLiteralType\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDecimalLiteral\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     50\u001b[0m     sc \u001b[38;5;241m=\u001b[39m get_active_spark_context()\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(JVMView, sc\u001b[38;5;241m.\u001b[39m_jvm)\u001b[38;5;241m.\u001b[39mfunctions\u001b[38;5;241m.\u001b[39mlit(literal)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pyspark/errors/exceptions/captured.py:175\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    171\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 175\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mSparkRuntimeException\u001b[0m: [UNSUPPORTED_FEATURE.LITERAL_TYPE] The feature is not supported: Literal for '[2]' of class java.util.ArrayList."
     ]
    }
   ],
   "source": [
    "filter_load_dim_df(dim_store, 'dim_store', 4, 'store_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e0aeffb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dim_date\n",
      "Filtering rows from dim_date\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/06 19:13:21 INFO SparkContext: Starting job: collect at /tmp/ipykernel_17573/1011261968.py:39\n",
      "23/12/06 19:13:21 INFO DAGScheduler: Got job 44 (collect at /tmp/ipykernel_17573/1011261968.py:39) with 1 output partitions\n",
      "23/12/06 19:13:21 INFO DAGScheduler: Final stage: ResultStage 44 (collect at /tmp/ipykernel_17573/1011261968.py:39)\n",
      "23/12/06 19:13:21 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/12/06 19:13:21 INFO DAGScheduler: Missing parents: List()\n",
      "23/12/06 19:13:21 INFO DAGScheduler: Submitting ResultStage 44 (MapPartitionsRDD[172] at collect at /tmp/ipykernel_17573/1011261968.py:39), which has no missing parents\n",
      "23/12/06 19:13:21 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 10.8 KiB, free 434.1 MiB)\n",
      "23/12/06 19:13:21 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 5.6 KiB, free 434.1 MiB)\n",
      "23/12/06 19:13:21 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on 192.168.42.129:43857 (size: 5.6 KiB, free: 434.3 MiB)\n",
      "23/12/06 19:13:21 INFO SparkContext: Created broadcast 50 from broadcast at DAGScheduler.scala:1580\n",
      "23/12/06 19:13:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 44 (MapPartitionsRDD[172] at collect at /tmp/ipykernel_17573/1011261968.py:39) (first 15 tasks are for partitions Vector(0))\n",
      "23/12/06 19:13:21 INFO TaskSchedulerImpl: Adding task set 44.0 with 1 tasks resource profile 0\n",
      "23/12/06 19:13:21 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 50) (192.168.42.129, executor driver, partition 0, PROCESS_LOCAL, 7643 bytes) \n",
      "23/12/06 19:13:21 INFO Executor: Running task 0.0 in stage 44.0 (TID 50)\n",
      "23/12/06 19:13:21 INFO JDBCRDD: closed connection\n",
      "23/12/06 19:13:21 INFO Executor: Finished task 0.0 in stage 44.0 (TID 50). 1445 bytes result sent to driver\n",
      "23/12/06 19:13:21 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 50) in 70 ms on 192.168.42.129 (executor driver) (1/1)\n",
      "23/12/06 19:13:21 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool \n",
      "23/12/06 19:13:21 INFO DAGScheduler: ResultStage 44 (collect at /tmp/ipykernel_17573/1011261968.py:39) finished in 0.086 s\n",
      "23/12/06 19:13:21 INFO DAGScheduler: Job 44 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/12/06 19:13:21 INFO TaskSchedulerImpl: Killing all running tasks in stage 44: Stage finished\n",
      "23/12/06 19:13:21 INFO DAGScheduler: Job 44 finished: collect at /tmp/ipykernel_17573/1011261968.py:39, took 0.099205 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dim_date\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/06 19:13:21 INFO FileSourceStrategy: Pushed Filters: IsNotNull(datekey)\n",
      "23/12/06 19:13:21 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(datekey#1267)\n",
      "23/12/06 19:13:21 INFO CodeGenerator: Code generated in 37.083803 ms\n",
      "23/12/06 19:13:21 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 200.0 KiB, free 433.9 MiB)\n",
      "23/12/06 19:13:21 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 34.5 KiB, free 433.9 MiB)\n",
      "23/12/06 19:13:21 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on 192.168.42.129:43857 (size: 34.5 KiB, free: 434.3 MiB)\n",
      "23/12/06 19:13:21 INFO BlockManagerInfo: Removed broadcast_50_piece0 on 192.168.42.129:43857 in memory (size: 5.6 KiB, free: 434.3 MiB)\n",
      "23/12/06 19:13:21 INFO SparkContext: Created broadcast 51 from jdbc at NativeMethodAccessorImpl.java:0\n",
      "23/12/06 19:13:21 INFO FileSourceScanExec: Planning scan with bin packing, max size: 5243081 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "23/12/06 19:13:21 INFO BlockManagerInfo: Removed broadcast_49_piece0 on 192.168.42.129:43857 in memory (size: 16.1 KiB, free: 434.3 MiB)\n",
      "23/12/06 19:13:22 INFO BlockManagerInfo: Removed broadcast_48_piece0 on 192.168.42.129:43857 in memory (size: 34.5 KiB, free: 434.4 MiB)\n",
      "23/12/06 19:13:22 INFO FileSourceStrategy: Pushed Filters: IsNotNull(datekey)\n",
      "23/12/06 19:13:22 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(datekey#1267)\n",
      "23/12/06 19:13:22 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 200.0 KiB, free 434.0 MiB)\n",
      "23/12/06 19:13:22 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 34.5 KiB, free 433.9 MiB)\n",
      "23/12/06 19:13:22 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on 192.168.42.129:43857 (size: 34.5 KiB, free: 434.3 MiB)\n",
      "23/12/06 19:13:22 INFO SparkContext: Created broadcast 52 from jdbc at NativeMethodAccessorImpl.java:0\n",
      "23/12/06 19:13:22 INFO FileSourceScanExec: Planning scan with bin packing, max size: 5243081 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "23/12/06 19:13:22 INFO SparkContext: Starting job: jdbc at NativeMethodAccessorImpl.java:0\n",
      "23/12/06 19:13:22 INFO DAGScheduler: Got job 45 (jdbc at NativeMethodAccessorImpl.java:0) with 4 output partitions\n",
      "23/12/06 19:13:22 INFO DAGScheduler: Final stage: ResultStage 45 (jdbc at NativeMethodAccessorImpl.java:0)\n",
      "23/12/06 19:13:22 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/12/06 19:13:22 INFO DAGScheduler: Missing parents: List()\n",
      "23/12/06 19:13:22 INFO DAGScheduler: Submitting ResultStage 45 (MapPartitionsRDD[185] at jdbc at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/12/06 19:13:22 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 35.6 KiB, free 433.9 MiB)\n",
      "23/12/06 19:13:22 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 16.5 KiB, free 433.9 MiB)\n",
      "23/12/06 19:13:22 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on 192.168.42.129:43857 (size: 16.5 KiB, free: 434.3 MiB)\n",
      "23/12/06 19:13:22 INFO SparkContext: Created broadcast 53 from broadcast at DAGScheduler.scala:1580\n",
      "23/12/06 19:13:22 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 45 (MapPartitionsRDD[185] at jdbc at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))\n",
      "23/12/06 19:13:22 INFO TaskSchedulerImpl: Adding task set 45.0 with 4 tasks resource profile 0\n",
      "23/12/06 19:13:22 INFO TaskSetManager: Starting task 0.0 in stage 45.0 (TID 51) (192.168.42.129, executor driver, partition 0, PROCESS_LOCAL, 8992 bytes) \n",
      "23/12/06 19:13:22 INFO TaskSetManager: Starting task 1.0 in stage 45.0 (TID 52) (192.168.42.129, executor driver, partition 1, PROCESS_LOCAL, 8992 bytes) \n",
      "23/12/06 19:13:22 INFO TaskSetManager: Starting task 2.0 in stage 45.0 (TID 53) (192.168.42.129, executor driver, partition 2, PROCESS_LOCAL, 8992 bytes) \n",
      "23/12/06 19:13:22 INFO TaskSetManager: Starting task 3.0 in stage 45.0 (TID 54) (192.168.42.129, executor driver, partition 3, PROCESS_LOCAL, 9476 bytes) \n",
      "23/12/06 19:13:22 INFO Executor: Running task 0.0 in stage 45.0 (TID 51)\n",
      "23/12/06 19:13:22 INFO Executor: Running task 1.0 in stage 45.0 (TID 52)\n",
      "23/12/06 19:13:22 INFO Executor: Running task 2.0 in stage 45.0 (TID 53)\n",
      "23/12/06 19:13:22 INFO Executor: Running task 3.0 in stage 45.0 (TID 54)\n",
      "23/12/06 19:13:22 INFO CodeGenerator: Code generated in 9.94832 ms\n",
      "23/12/06 19:13:22 INFO CodeGenerator: Code generated in 21.508282 ms\n",
      "23/12/06 19:13:22 INFO FileScanRDD: Reading File path: file:///home/me/folder_1/gitfolder/ETL-pyspark-airflow-postgres/dags/transformed_data/2011-01-01%2000:00:00/dim_date/part-00007-737bff0c-9bd3-4856-a532-f340d741011e-c000.csv, range: 0-155, partition values: [empty row]\n",
      "23/12/06 19:13:22 INFO FileScanRDD: Reading File path: file:///home/me/folder_1/gitfolder/ETL-pyspark-airflow-postgres/dags/transformed_data/2011-01-01%2000:00:00/dim_date/part-00009-737bff0c-9bd3-4856-a532-f340d741011e-c000.csv, range: 0-190, partition values: [empty row]\n",
      "23/12/06 19:13:22 INFO FileScanRDD: Reading File path: file:///home/me/folder_1/gitfolder/ETL-pyspark-airflow-postgres/dags/transformed_data/2011-01-01%2000:00:00/dim_date/part-00003-737bff0c-9bd3-4856-a532-f340d741011e-c000.csv, range: 0-155, partition values: [empty row]\n",
      "23/12/06 19:13:22 INFO FileScanRDD: Reading File path: file:///home/me/folder_1/gitfolder/ETL-pyspark-airflow-postgres/dags/transformed_data/2011-01-01%2000:00:00/dim_date/part-00004-737bff0c-9bd3-4856-a532-f340d741011e-c000.csv, range: 0-154, partition values: [empty row]\n",
      "23/12/06 19:13:22 INFO CodeGenerator: Code generated in 23.391962 ms\n",
      "23/12/06 19:13:22 INFO CodeGenerator: Code generated in 16.397878 ms\n",
      "23/12/06 19:13:22 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: date, date_key, year, month, day, quarter, dayofweek\n",
      " Schema: date, datekey, year, month, day, quarter, dayofweek\n",
      "Expected: datekey but found: date_key\n",
      "CSV file: file:///home/me/folder_1/gitfolder/ETL-pyspark-airflow-postgres/dags/transformed_data/2011-01-01%2000:00:00/dim_date/part-00009-737bff0c-9bd3-4856-a532-f340d741011e-c000.csv\n",
      "23/12/06 19:13:22 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: date, date_key, year, month, day, quarter, dayofweek\n",
      " Schema: date, datekey, year, month, day, quarter, dayofweek\n",
      "Expected: datekey but found: date_key\n",
      "CSV file: file:///home/me/folder_1/gitfolder/ETL-pyspark-airflow-postgres/dags/transformed_data/2011-01-01%2000:00:00/dim_date/part-00003-737bff0c-9bd3-4856-a532-f340d741011e-c000.csv\n",
      "23/12/06 19:13:22 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: date, date_key, year, month, day, quarter, dayofweek\n",
      " Schema: date, datekey, year, month, day, quarter, dayofweek\n",
      "Expected: datekey but found: date_key\n",
      "CSV file: file:///home/me/folder_1/gitfolder/ETL-pyspark-airflow-postgres/dags/transformed_data/2011-01-01%2000:00:00/dim_date/part-00007-737bff0c-9bd3-4856-a532-f340d741011e-c000.csv\n",
      "23/12/06 19:13:22 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: date, date_key, year, month, day, quarter, dayofweek\n",
      " Schema: date, datekey, year, month, day, quarter, dayofweek\n",
      "Expected: datekey but found: date_key\n",
      "CSV file: file:///home/me/folder_1/gitfolder/ETL-pyspark-airflow-postgres/dags/transformed_data/2011-01-01%2000:00:00/dim_date/part-00004-737bff0c-9bd3-4856-a532-f340d741011e-c000.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load for dim_date done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/06 19:13:22 INFO FileScanRDD: Reading File path: file:///home/me/folder_1/gitfolder/ETL-pyspark-airflow-postgres/dags/transformed_data/2011-01-01%2000:00:00/dim_date/part-00008-737bff0c-9bd3-4856-a532-f340d741011e-c000.csv, range: 0-155, partition values: [empty row]\n",
      "23/12/06 19:13:22 INFO FileScanRDD: Reading File path: file:///home/me/folder_1/gitfolder/ETL-pyspark-airflow-postgres/dags/transformed_data/2011-01-01%2000:00:00/dim_date/part-00005-737bff0c-9bd3-4856-a532-f340d741011e-c000.csv, range: 0-155, partition values: [empty row]\n",
      "23/12/06 19:13:22 INFO FileScanRDD: Reading File path: file:///home/me/folder_1/gitfolder/ETL-pyspark-airflow-postgres/dags/transformed_data/2011-01-01%2000:00:00/dim_date/part-00001-737bff0c-9bd3-4856-a532-f340d741011e-c000.csv, range: 0-154, partition values: [empty row]\n",
      "23/12/06 19:13:22 INFO FileScanRDD: Reading File path: file:///home/me/folder_1/gitfolder/ETL-pyspark-airflow-postgres/dags/transformed_data/2011-01-01%2000:00:00/dim_date/part-00000-737bff0c-9bd3-4856-a532-f340d741011e-c000.csv, range: 0-189, partition values: [empty row]\n",
      "23/12/06 19:13:22 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: date, date_key, year, month, day, quarter, dayofweek\n",
      " Schema: date, datekey, year, month, day, quarter, dayofweek\n",
      "Expected: datekey but found: date_key\n",
      "CSV file: file:///home/me/folder_1/gitfolder/ETL-pyspark-airflow-postgres/dags/transformed_data/2011-01-01%2000:00:00/dim_date/part-00001-737bff0c-9bd3-4856-a532-f340d741011e-c000.csv\n",
      "23/12/06 19:13:22 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: date, date_key, year, month, day, quarter, dayofweek\n",
      " Schema: date, datekey, year, month, day, quarter, dayofweek\n",
      "Expected: datekey but found: date_key\n",
      "CSV file: file:///home/me/folder_1/gitfolder/ETL-pyspark-airflow-postgres/dags/transformed_data/2011-01-01%2000:00:00/dim_date/part-00008-737bff0c-9bd3-4856-a532-f340d741011e-c000.csv\n",
      "23/12/06 19:13:22 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: date, date_key, year, month, day, quarter, dayofweek\n",
      " Schema: date, datekey, year, month, day, quarter, dayofweek\n",
      "Expected: datekey but found: date_key\n",
      "CSV file: file:///home/me/folder_1/gitfolder/ETL-pyspark-airflow-postgres/dags/transformed_data/2011-01-01%2000:00:00/dim_date/part-00005-737bff0c-9bd3-4856-a532-f340d741011e-c000.csv\n",
      "23/12/06 19:13:22 INFO FileScanRDD: Reading File path: file:///home/me/folder_1/gitfolder/ETL-pyspark-airflow-postgres/dags/transformed_data/2011-01-01%2000:00:00/dim_date/part-00006-737bff0c-9bd3-4856-a532-f340d741011e-c000.csv, range: 0-154, partition values: [empty row]\n",
      "23/12/06 19:13:22 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: date, date_key, year, month, day, quarter, dayofweek\n",
      " Schema: date, datekey, year, month, day, quarter, dayofweek\n",
      "Expected: datekey but found: date_key\n",
      "CSV file: file:///home/me/folder_1/gitfolder/ETL-pyspark-airflow-postgres/dags/transformed_data/2011-01-01%2000:00:00/dim_date/part-00000-737bff0c-9bd3-4856-a532-f340d741011e-c000.csv\n",
      "23/12/06 19:13:22 INFO Executor: Finished task 1.0 in stage 45.0 (TID 52). 1648 bytes result sent to driver\n",
      "23/12/06 19:13:22 INFO Executor: Finished task 2.0 in stage 45.0 (TID 53). 1648 bytes result sent to driver\n",
      "23/12/06 19:13:22 INFO TaskSetManager: Finished task 1.0 in stage 45.0 (TID 52) in 499 ms on 192.168.42.129 (executor driver) (1/4)\n",
      "23/12/06 19:13:22 INFO TaskSetManager: Finished task 2.0 in stage 45.0 (TID 53) in 499 ms on 192.168.42.129 (executor driver) (2/4)\n",
      "23/12/06 19:13:22 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: date, date_key, year, month, day, quarter, dayofweek\n",
      " Schema: date, datekey, year, month, day, quarter, dayofweek\n",
      "Expected: datekey but found: date_key\n",
      "CSV file: file:///home/me/folder_1/gitfolder/ETL-pyspark-airflow-postgres/dags/transformed_data/2011-01-01%2000:00:00/dim_date/part-00006-737bff0c-9bd3-4856-a532-f340d741011e-c000.csv\n",
      "23/12/06 19:13:22 INFO Executor: Finished task 0.0 in stage 45.0 (TID 51). 1648 bytes result sent to driver\n",
      "23/12/06 19:13:22 INFO TaskSetManager: Finished task 0.0 in stage 45.0 (TID 51) in 505 ms on 192.168.42.129 (executor driver) (3/4)\n",
      "23/12/06 19:13:22 INFO FileScanRDD: Reading File path: file:///home/me/folder_1/gitfolder/ETL-pyspark-airflow-postgres/dags/transformed_data/2011-01-01%2000:00:00/dim_date/part-00002-737bff0c-9bd3-4856-a532-f340d741011e-c000.csv, range: 0-154, partition values: [empty row]\n",
      "23/12/06 19:13:22 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: date, date_key, year, month, day, quarter, dayofweek\n",
      " Schema: date, datekey, year, month, day, quarter, dayofweek\n",
      "Expected: datekey but found: date_key\n",
      "CSV file: file:///home/me/folder_1/gitfolder/ETL-pyspark-airflow-postgres/dags/transformed_data/2011-01-01%2000:00:00/dim_date/part-00002-737bff0c-9bd3-4856-a532-f340d741011e-c000.csv\n",
      "23/12/06 19:13:22 INFO Executor: Finished task 3.0 in stage 45.0 (TID 54). 1691 bytes result sent to driver\n",
      "23/12/06 19:13:22 INFO TaskSetManager: Finished task 3.0 in stage 45.0 (TID 54) in 532 ms on 192.168.42.129 (executor driver) (4/4)\n",
      "23/12/06 19:13:22 INFO TaskSchedulerImpl: Removed TaskSet 45.0, whose tasks have all completed, from pool \n",
      "23/12/06 19:13:22 INFO DAGScheduler: ResultStage 45 (jdbc at NativeMethodAccessorImpl.java:0) finished in 0.569 s\n",
      "23/12/06 19:13:22 INFO DAGScheduler: Job 45 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/12/06 19:13:22 INFO TaskSchedulerImpl: Killing all running tasks in stage 45: Stage finished\n",
      "23/12/06 19:13:22 INFO DAGScheduler: Job 45 finished: jdbc at NativeMethodAccessorImpl.java:0, took 0.579557 s\n"
     ]
    }
   ],
   "source": [
    "filter_load_dim_df(dim_date, 'dim_date', 4, 'datekey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d99489a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading fact_sale\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/06 19:40:21 INFO FileSourceStrategy: Pushed Filters: \n",
      "23/12/06 19:40:21 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "23/12/06 19:40:21 INFO MemoryStore: Block broadcast_73 stored as values in memory (estimated size 200.0 KiB, free 434.2 MiB)\n",
      "23/12/06 19:40:21 INFO MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 34.5 KiB, free 434.2 MiB)\n",
      "23/12/06 19:40:21 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on 192.168.42.129:43857 (size: 34.5 KiB, free: 434.4 MiB)\n",
      "23/12/06 19:40:21 INFO SparkContext: Created broadcast 73 from jdbc at <unknown>:0\n",
      "23/12/06 19:40:21 INFO FileSourceScanExec: Planning scan with bin packing, max size: 5444325 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "23/12/06 19:40:21 INFO FileSourceStrategy: Pushed Filters: \n",
      "23/12/06 19:40:21 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "23/12/06 19:40:21 INFO MemoryStore: Block broadcast_74 stored as values in memory (estimated size 200.0 KiB, free 434.0 MiB)\n",
      "23/12/06 19:40:21 INFO MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 34.5 KiB, free 433.9 MiB)\n",
      "23/12/06 19:40:21 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on 192.168.42.129:43857 (size: 34.5 KiB, free: 434.3 MiB)\n",
      "23/12/06 19:40:21 INFO SparkContext: Created broadcast 74 from jdbc at <unknown>:0\n",
      "23/12/06 19:40:21 INFO FileSourceScanExec: Planning scan with bin packing, max size: 5444325 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "23/12/06 19:40:21 INFO SparkContext: Starting job: jdbc at <unknown>:0\n",
      "23/12/06 19:40:21 INFO DAGScheduler: Got job 55 (jdbc at <unknown>:0) with 4 output partitions\n",
      "23/12/06 19:40:21 INFO DAGScheduler: Final stage: ResultStage 55 (jdbc at <unknown>:0)\n",
      "23/12/06 19:40:21 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/12/06 19:40:21 INFO DAGScheduler: Missing parents: List()\n",
      "23/12/06 19:40:21 INFO DAGScheduler: Submitting ResultStage 55 (MapPartitionsRDD[265] at jdbc at <unknown>:0), which has no missing parents\n",
      "23/12/06 19:40:21 INFO MemoryStore: Block broadcast_75 stored as values in memory (estimated size 23.6 KiB, free 433.9 MiB)\n",
      "23/12/06 19:40:21 INFO MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 11.3 KiB, free 433.9 MiB)\n",
      "23/12/06 19:40:21 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on 192.168.42.129:43857 (size: 11.3 KiB, free: 434.3 MiB)\n",
      "23/12/06 19:40:21 INFO SparkContext: Created broadcast 75 from broadcast at DAGScheduler.scala:1580\n",
      "23/12/06 19:40:21 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 55 (MapPartitionsRDD[265] at jdbc at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))\n",
      "23/12/06 19:40:21 INFO TaskSchedulerImpl: Adding task set 55.0 with 4 tasks resource profile 0\n",
      "23/12/06 19:40:21 INFO TaskSetManager: Starting task 0.0 in stage 55.0 (TID 79) (192.168.42.129, executor driver, partition 0, PROCESS_LOCAL, 8996 bytes) \n",
      "23/12/06 19:40:21 INFO TaskSetManager: Starting task 1.0 in stage 55.0 (TID 80) (192.168.42.129, executor driver, partition 1, PROCESS_LOCAL, 8996 bytes) \n",
      "23/12/06 19:40:21 INFO TaskSetManager: Starting task 2.0 in stage 55.0 (TID 81) (192.168.42.129, executor driver, partition 2, PROCESS_LOCAL, 8996 bytes) \n",
      "23/12/06 19:40:21 INFO TaskSetManager: Starting task 3.0 in stage 55.0 (TID 82) (192.168.42.129, executor driver, partition 3, PROCESS_LOCAL, 9484 bytes) \n",
      "23/12/06 19:40:21 INFO Executor: Running task 1.0 in stage 55.0 (TID 80)\n",
      "23/12/06 19:40:21 INFO Executor: Running task 2.0 in stage 55.0 (TID 81)\n",
      "23/12/06 19:40:21 INFO Executor: Running task 3.0 in stage 55.0 (TID 82)\n",
      "23/12/06 19:40:21 INFO Executor: Running task 0.0 in stage 55.0 (TID 79)\n",
      "23/12/06 19:40:21 INFO FileScanRDD: Reading File path: file:///home/me/folder_1/gitfolder/ETL-pyspark-airflow-postgres/dags/transformed_data/2011-01-01%2000:00:00/fact_sales/part-00008-eb47a012-f918-47a7-9342-23801aa9b1f8-c000.csv, range: 0-161100, partition values: [empty row]\n",
      "23/12/06 19:40:21 INFO FileScanRDD: Reading File path: file:///home/me/folder_1/gitfolder/ETL-pyspark-airflow-postgres/dags/transformed_data/2011-01-01%2000:00:00/fact_sales/part-00009-eb47a012-f918-47a7-9342-23801aa9b1f8-c000.csv, range: 0-161266, partition values: [empty row]\n",
      "23/12/06 19:40:21 INFO FileScanRDD: Reading File path: file:///home/me/folder_1/gitfolder/ETL-pyspark-airflow-postgres/dags/transformed_data/2011-01-01%2000:00:00/fact_sales/part-00002-eb47a012-f918-47a7-9342-23801aa9b1f8-c000.csv, range: 0-161209, partition values: [empty row]\n",
      "23/12/06 19:40:21 INFO FileScanRDD: Reading File path: file:///home/me/folder_1/gitfolder/ETL-pyspark-airflow-postgres/dags/transformed_data/2011-01-01%2000:00:00/fact_sales/part-00000-eb47a012-f918-47a7-9342-23801aa9b1f8-c000.csv, range: 0-161314, partition values: [empty row]\n",
      "23/12/06 19:40:21 ERROR Executor: Exception in task 2.0 in stage 55.0 (TID 81)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO fact_sale (\"payment_id\",\"customer_id\",\"film_id\",\"store_id\",\"payment_date\",\"sale_amount\",\"rental_date\",\"return_date\") VALUES (29145,14,591,2,'2007-04-09 14:38:51.996+08'::timestamp,7.99,'2005-07-09 16:10:25+08'::timestamp,'2005-07-18 17:10:25+08'::timestamp) was aborted: ERROR: duplicate key value violates unique constraint \"fact_sale_2007h1_pkey\"\n",
      "  Detail: Key (payment_id, payment_date)=(29145, 2007-04-09 14:38:51.996) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:170)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2133)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1490)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1515)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:559)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:905)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:928)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1685)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:746)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"fact_sale_2007h1_pkey\"\n",
      "  Detail: Key (payment_id, payment_date)=(29145, 2007-04-09 14:38:51.996) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)\n",
      "\t... 24 more\n",
      "23/12/06 19:40:21 WARN TaskSetManager: Lost task 2.0 in stage 55.0 (TID 81) (192.168.42.129 executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO fact_sale (\"payment_id\",\"customer_id\",\"film_id\",\"store_id\",\"payment_date\",\"sale_amount\",\"rental_date\",\"return_date\") VALUES (29145,14,591,2,'2007-04-09 14:38:51.996+08'::timestamp,7.99,'2005-07-09 16:10:25+08'::timestamp,'2005-07-18 17:10:25+08'::timestamp) was aborted: ERROR: duplicate key value violates unique constraint \"fact_sale_2007h1_pkey\"\n",
      "  Detail: Key (payment_id, payment_date)=(29145, 2007-04-09 14:38:51.996) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:170)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2133)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1490)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1515)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:559)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:905)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:928)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1685)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:746)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"fact_sale_2007h1_pkey\"\n",
      "  Detail: Key (payment_id, payment_date)=(29145, 2007-04-09 14:38:51.996) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)\n",
      "\t... 24 more\n",
      "\n",
      "23/12/06 19:40:21 ERROR TaskSetManager: Task 2 in stage 55.0 failed 1 times; aborting job\n",
      "23/12/06 19:40:21 INFO TaskSchedulerImpl: Cancelling stage 55\n",
      "23/12/06 19:40:21 INFO TaskSchedulerImpl: Killing all running tasks in stage 55: Stage cancelled: Job aborted due to stage failure: Task 2 in stage 55.0 failed 1 times, most recent failure: Lost task 2.0 in stage 55.0 (TID 81) (192.168.42.129 executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO fact_sale (\"payment_id\",\"customer_id\",\"film_id\",\"store_id\",\"payment_date\",\"sale_amount\",\"rental_date\",\"return_date\") VALUES (29145,14,591,2,'2007-04-09 14:38:51.996+08'::timestamp,7.99,'2005-07-09 16:10:25+08'::timestamp,'2005-07-18 17:10:25+08'::timestamp) was aborted: ERROR: duplicate key value violates unique constraint \"fact_sale_2007h1_pkey\"\n",
      "  Detail: Key (payment_id, payment_date)=(29145, 2007-04-09 14:38:51.996) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:170)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2133)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1490)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1515)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:559)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:905)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:928)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1685)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:746)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"fact_sale_2007h1_pkey\"\n",
      "  Detail: Key (payment_id, payment_date)=(29145, 2007-04-09 14:38:51.996) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)\n",
      "\t... 24 more\n",
      "\n",
      "Driver stacktrace:\n",
      "23/12/06 19:40:21 INFO TaskSchedulerImpl: Stage 55 was cancelled\n",
      "23/12/06 19:40:21 INFO DAGScheduler: ResultStage 55 (jdbc at <unknown>:0) failed in 0.275 s due to Job aborted due to stage failure: Task 2 in stage 55.0 failed 1 times, most recent failure: Lost task 2.0 in stage 55.0 (TID 81) (192.168.42.129 executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO fact_sale (\"payment_id\",\"customer_id\",\"film_id\",\"store_id\",\"payment_date\",\"sale_amount\",\"rental_date\",\"return_date\") VALUES (29145,14,591,2,'2007-04-09 14:38:51.996+08'::timestamp,7.99,'2005-07-09 16:10:25+08'::timestamp,'2005-07-18 17:10:25+08'::timestamp) was aborted: ERROR: duplicate key value violates unique constraint \"fact_sale_2007h1_pkey\"\n",
      "  Detail: Key (payment_id, payment_date)=(29145, 2007-04-09 14:38:51.996) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:170)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2133)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1490)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1515)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:559)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:905)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:928)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1685)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:746)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"fact_sale_2007h1_pkey\"\n",
      "  Detail: Key (payment_id, payment_date)=(29145, 2007-04-09 14:38:51.996) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)\n",
      "\t... 24 more\n",
      "\n",
      "Driver stacktrace:\n",
      "23/12/06 19:40:21 INFO Executor: Executor is trying to kill task 3.0 in stage 55.0 (TID 82), reason: Stage cancelled: Job aborted due to stage failure: Task 2 in stage 55.0 failed 1 times, most recent failure: Lost task 2.0 in stage 55.0 (TID 81) (192.168.42.129 executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO fact_sale (\"payment_id\",\"customer_id\",\"film_id\",\"store_id\",\"payment_date\",\"sale_amount\",\"rental_date\",\"return_date\") VALUES (29145,14,591,2,'2007-04-09 14:38:51.996+08'::timestamp,7.99,'2005-07-09 16:10:25+08'::timestamp,'2005-07-18 17:10:25+08'::timestamp) was aborted: ERROR: duplicate key value violates unique constraint \"fact_sale_2007h1_pkey\"\n",
      "  Detail: Key (payment_id, payment_date)=(29145, 2007-04-09 14:38:51.996) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:170)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2133)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1490)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1515)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:559)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:905)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:928)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1685)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:746)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"fact_sale_2007h1_pkey\"\n",
      "  Detail: Key (payment_id, payment_date)=(29145, 2007-04-09 14:38:51.996) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)\n",
      "\t... 24 more\n",
      "\n",
      "Driver stacktrace:\n",
      "23/12/06 19:40:21 INFO Executor: Executor is trying to kill task 0.0 in stage 55.0 (TID 79), reason: Stage cancelled: Job aborted due to stage failure: Task 2 in stage 55.0 failed 1 times, most recent failure: Lost task 2.0 in stage 55.0 (TID 81) (192.168.42.129 executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO fact_sale (\"payment_id\",\"customer_id\",\"film_id\",\"store_id\",\"payment_date\",\"sale_amount\",\"rental_date\",\"return_date\") VALUES (29145,14,591,2,'2007-04-09 14:38:51.996+08'::timestamp,7.99,'2005-07-09 16:10:25+08'::timestamp,'2005-07-18 17:10:25+08'::timestamp) was aborted: ERROR: duplicate key value violates unique constraint \"fact_sale_2007h1_pkey\"\n",
      "  Detail: Key (payment_id, payment_date)=(29145, 2007-04-09 14:38:51.996) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:170)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2133)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1490)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1515)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:559)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:905)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:928)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1685)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:746)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"fact_sale_2007h1_pkey\"\n",
      "  Detail: Key (payment_id, payment_date)=(29145, 2007-04-09 14:38:51.996) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)\n",
      "\t... 24 more\n",
      "\n",
      "Driver stacktrace:\n",
      "23/12/06 19:40:21 INFO Executor: Executor is trying to kill task 1.0 in stage 55.0 (TID 80), reason: Stage cancelled: Job aborted due to stage failure: Task 2 in stage 55.0 failed 1 times, most recent failure: Lost task 2.0 in stage 55.0 (TID 81) (192.168.42.129 executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO fact_sale (\"payment_id\",\"customer_id\",\"film_id\",\"store_id\",\"payment_date\",\"sale_amount\",\"rental_date\",\"return_date\") VALUES (29145,14,591,2,'2007-04-09 14:38:51.996+08'::timestamp,7.99,'2005-07-09 16:10:25+08'::timestamp,'2005-07-18 17:10:25+08'::timestamp) was aborted: ERROR: duplicate key value violates unique constraint \"fact_sale_2007h1_pkey\"\n",
      "  Detail: Key (payment_id, payment_date)=(29145, 2007-04-09 14:38:51.996) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:170)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2133)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1490)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1515)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:559)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:905)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:928)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1685)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:746)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"fact_sale_2007h1_pkey\"\n",
      "  Detail: Key (payment_id, payment_date)=(29145, 2007-04-09 14:38:51.996) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)\n",
      "\t... 24 more\n",
      "\n",
      "Driver stacktrace:\n",
      "23/12/06 19:40:21 INFO DAGScheduler: Job 55 failed: jdbc at <unknown>:0, took 0.293466 s\n",
      "23/12/06 19:40:21 INFO Executor: Executor killed task 3.0 in stage 55.0 (TID 82), reason: Stage cancelled: Job aborted due to stage failure: Task 2 in stage 55.0 failed 1 times, most recent failure: Lost task 2.0 in stage 55.0 (TID 81) (192.168.42.129 executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO fact_sale (\"payment_id\",\"customer_id\",\"film_id\",\"store_id\",\"payment_date\",\"sale_amount\",\"rental_date\",\"return_date\") VALUES (29145,14,591,2,'2007-04-09 14:38:51.996+08'::timestamp,7.99,'2005-07-09 16:10:25+08'::timestamp,'2005-07-18 17:10:25+08'::timestamp) was aborted: ERROR: duplicate key value violates unique constraint \"fact_sale_2007h1_pkey\"\n",
      "  Detail: Key (payment_id, payment_date)=(29145, 2007-04-09 14:38:51.996) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:170)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2133)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1490)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1515)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:559)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:905)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:928)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1685)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:746)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"fact_sale_2007h1_pkey\"\n",
      "  Detail: Key (payment_id, payment_date)=(29145, 2007-04-09 14:38:51.996) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)\n",
      "\t... 24 more\n",
      "\n",
      "Driver stacktrace:\n",
      "23/12/06 19:40:21 INFO Executor: Executor interrupted and killed task 1.0 in stage 55.0 (TID 80), reason: Stage cancelled: Job aborted due to stage failure: Task 2 in stage 55.0 failed 1 times, most recent failure: Lost task 2.0 in stage 55.0 (TID 81) (192.168.42.129 executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO fact_sale (\"payment_id\",\"customer_id\",\"film_id\",\"store_id\",\"payment_date\",\"sale_amount\",\"rental_date\",\"return_date\") VALUES (29145,14,591,2,'2007-04-09 14:38:51.996+08'::timestamp,7.99,'2005-07-09 16:10:25+08'::timestamp,'2005-07-18 17:10:25+08'::timestamp) was aborted: ERROR: duplicate key value violates unique constraint \"fact_sale_2007h1_pkey\"\n",
      "  Detail: Key (payment_id, payment_date)=(29145, 2007-04-09 14:38:51.996) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:170)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2133)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1490)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1515)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:559)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:905)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:928)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1685)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:746)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"fact_sale_2007h1_pkey\"\n",
      "  Detail: Key (payment_id, payment_date)=(29145, 2007-04-09 14:38:51.996) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)\n",
      "\t... 24 more\n",
      "\n",
      "Driver stacktrace:\n",
      "23/12/06 19:40:21 INFO Executor: Executor killed task 0.0 in stage 55.0 (TID 79), reason: Stage cancelled: Job aborted due to stage failure: Task 2 in stage 55.0 failed 1 times, most recent failure: Lost task 2.0 in stage 55.0 (TID 81) (192.168.42.129 executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO fact_sale (\"payment_id\",\"customer_id\",\"film_id\",\"store_id\",\"payment_date\",\"sale_amount\",\"rental_date\",\"return_date\") VALUES (29145,14,591,2,'2007-04-09 14:38:51.996+08'::timestamp,7.99,'2005-07-09 16:10:25+08'::timestamp,'2005-07-18 17:10:25+08'::timestamp) was aborted: ERROR: duplicate key value violates unique constraint \"fact_sale_2007h1_pkey\"\n",
      "  Detail: Key (payment_id, payment_date)=(29145, 2007-04-09 14:38:51.996) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:170)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2133)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1490)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1515)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:559)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:905)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:928)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1685)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:746)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"fact_sale_2007h1_pkey\"\n",
      "  Detail: Key (payment_id, payment_date)=(29145, 2007-04-09 14:38:51.996) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)\n",
      "\t... 24 more\n",
      "\n",
      "Driver stacktrace:\n",
      "23/12/06 19:40:21 WARN TaskSetManager: Lost task 3.0 in stage 55.0 (TID 82) (192.168.42.129 executor driver): TaskKilled (Stage cancelled: Job aborted due to stage failure: Task 2 in stage 55.0 failed 1 times, most recent failure: Lost task 2.0 in stage 55.0 (TID 81) (192.168.42.129 executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO fact_sale (\"payment_id\",\"customer_id\",\"film_id\",\"store_id\",\"payment_date\",\"sale_amount\",\"rental_date\",\"return_date\") VALUES (29145,14,591,2,'2007-04-09 14:38:51.996+08'::timestamp,7.99,'2005-07-09 16:10:25+08'::timestamp,'2005-07-18 17:10:25+08'::timestamp) was aborted: ERROR: duplicate key value violates unique constraint \"fact_sale_2007h1_pkey\"\n",
      "  Detail: Key (payment_id, payment_date)=(29145, 2007-04-09 14:38:51.996) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:170)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2133)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1490)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1515)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:559)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:905)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:928)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1685)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:746)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"fact_sale_2007h1_pkey\"\n",
      "  Detail: Key (payment_id, payment_date)=(29145, 2007-04-09 14:38:51.996) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)\n",
      "\t... 24 more\n",
      "\n",
      "Driver stacktrace:)\n",
      "23/12/06 19:40:21 INFO TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool \n",
      "23/12/06 19:40:21 WARN TaskSetManager: Lost task 1.0 in stage 55.0 (TID 80) (192.168.42.129 executor driver): TaskKilled (Stage cancelled: Job aborted due to stage failure: Task 2 in stage 55.0 failed 1 times, most recent failure: Lost task 2.0 in stage 55.0 (TID 81) (192.168.42.129 executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO fact_sale (\"payment_id\",\"customer_id\",\"film_id\",\"store_id\",\"payment_date\",\"sale_amount\",\"rental_date\",\"return_date\") VALUES (29145,14,591,2,'2007-04-09 14:38:51.996+08'::timestamp,7.99,'2005-07-09 16:10:25+08'::timestamp,'2005-07-18 17:10:25+08'::timestamp) was aborted: ERROR: duplicate key value violates unique constraint \"fact_sale_2007h1_pkey\"\n",
      "  Detail: Key (payment_id, payment_date)=(29145, 2007-04-09 14:38:51.996) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:170)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2133)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1490)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1515)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:559)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:905)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:928)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1685)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:746)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"fact_sale_2007h1_pkey\"\n",
      "  Detail: Key (payment_id, payment_date)=(29145, 2007-04-09 14:38:51.996) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)\n",
      "\t... 24 more\n",
      "\n",
      "Driver stacktrace:)\n",
      "23/12/06 19:40:21 INFO TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool \n",
      "23/12/06 19:40:21 WARN TaskSetManager: Lost task 0.0 in stage 55.0 (TID 79) (192.168.42.129 executor driver): TaskKilled (Stage cancelled: Job aborted due to stage failure: Task 2 in stage 55.0 failed 1 times, most recent failure: Lost task 2.0 in stage 55.0 (TID 81) (192.168.42.129 executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO fact_sale (\"payment_id\",\"customer_id\",\"film_id\",\"store_id\",\"payment_date\",\"sale_amount\",\"rental_date\",\"return_date\") VALUES (29145,14,591,2,'2007-04-09 14:38:51.996+08'::timestamp,7.99,'2005-07-09 16:10:25+08'::timestamp,'2005-07-18 17:10:25+08'::timestamp) was aborted: ERROR: duplicate key value violates unique constraint \"fact_sale_2007h1_pkey\"\n",
      "  Detail: Key (payment_id, payment_date)=(29145, 2007-04-09 14:38:51.996) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:170)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2133)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1490)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1515)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:559)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:905)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:928)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1685)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:746)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"fact_sale_2007h1_pkey\"\n",
      "  Detail: Key (payment_id, payment_date)=(29145, 2007-04-09 14:38:51.996) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)\n",
      "\t... 24 more\n",
      "\n",
      "Driver stacktrace:)\n",
      "23/12/06 19:40:21 INFO TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool \n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o860.jdbc.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 2 in stage 55.0 failed 1 times, most recent failure: Lost task 2.0 in stage 55.0 (TID 81) (192.168.42.129 executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO fact_sale (\"payment_id\",\"customer_id\",\"film_id\",\"store_id\",\"payment_date\",\"sale_amount\",\"rental_date\",\"return_date\") VALUES (29145,14,591,2,'2007-04-09 14:38:51.996+08'::timestamp,7.99,'2005-07-09 16:10:25+08'::timestamp,'2005-07-18 17:10:25+08'::timestamp) was aborted: ERROR: duplicate key value violates unique constraint \"fact_sale_2007h1_pkey\"\n  Detail: Key (payment_id, payment_date)=(29145, 2007-04-09 14:38:51.996) already exists.  Call getNextException to see other errors in the batch.\n\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:170)\n\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)\n\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2133)\n\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1490)\n\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1515)\n\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:559)\n\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:905)\n\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:928)\n\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1685)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:746)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)\n\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\nCaused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"fact_sale_2007h1_pkey\"\n  Detail: Key (payment_id, payment_date)=(29145, 2007-04-09 14:38:51.996) already exists.\n\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)\n\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)\n\t... 24 more\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2844)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2780)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2779)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2779)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1242)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1242)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1242)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3048)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2982)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2971)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:984)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2419)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2438)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2463)\n\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$1(RDD.scala:1036)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:407)\n\tat org.apache.spark.rdd.RDD.foreachPartition(RDD.scala:1034)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.saveTable(JdbcUtils.scala:901)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:70)\n\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n\tat org.apache.spark.sql.DataFrameWriter.jdbc(DataFrameWriter.scala:756)\n\tat jdk.internal.reflect.GeneratedMethodAccessor84.invoke(Unknown Source)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\nCaused by: java.sql.BatchUpdateException: Batch entry 0 INSERT INTO fact_sale (\"payment_id\",\"customer_id\",\"film_id\",\"store_id\",\"payment_date\",\"sale_amount\",\"rental_date\",\"return_date\") VALUES (29145,14,591,2,'2007-04-09 14:38:51.996+08'::timestamp,7.99,'2005-07-09 16:10:25+08'::timestamp,'2005-07-18 17:10:25+08'::timestamp) was aborted: ERROR: duplicate key value violates unique constraint \"fact_sale_2007h1_pkey\"\n  Detail: Key (payment_id, payment_date)=(29145, 2007-04-09 14:38:51.996) already exists.  Call getNextException to see other errors in the batch.\n\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:170)\n\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)\n\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2133)\n\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1490)\n\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1515)\n\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:559)\n\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:905)\n\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:928)\n\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1685)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:746)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)\n\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\t... 1 more\nCaused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"fact_sale_2007h1_pkey\"\n  Detail: Key (payment_id, payment_date)=(29145, 2007-04-09 14:38:51.996) already exists.\n\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)\n\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)\n\t... 24 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[128], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m load_fact_df(fact_sale, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfact_sale\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m4\u001b[39m)\n",
      "Cell \u001b[0;32mIn[126], line 49\u001b[0m, in \u001b[0;36mload_fact_df\u001b[0;34m(df, table, partitions)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_fact_df\u001b[39m(df, table, partitions):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtable\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 49\u001b[0m     write_df(df, table, partitions)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoad for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtable\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m done\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[126], line 27\u001b[0m, in \u001b[0;36mwrite_df\u001b[0;34m(df, table, partitions)\u001b[0m\n\u001b[1;32m     19\u001b[0m postgres_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjdbc:postgresql://localhost:5432/alabama\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     20\u001b[0m properties \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmy_user\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassword\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmy_user_1\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124misolationLevel\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSERIALIZABLE\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     26\u001b[0m }\n\u001b[0;32m---> 27\u001b[0m df\u001b[38;5;241m.\u001b[39mwrite\u001b[38;5;241m.\u001b[39mjdbc(url\u001b[38;5;241m=\u001b[39mpostgres_url, table\u001b[38;5;241m=\u001b[39mtable, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mappend\u001b[39m\u001b[38;5;124m\"\u001b[39m, properties\u001b[38;5;241m=\u001b[39mproperties)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pyspark/sql/readwriter.py:1919\u001b[0m, in \u001b[0;36mDataFrameWriter.jdbc\u001b[0;34m(self, url, table, mode, properties)\u001b[0m\n\u001b[1;32m   1917\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m properties:\n\u001b[1;32m   1918\u001b[0m     jprop\u001b[38;5;241m.\u001b[39msetProperty(k, properties[k])\n\u001b[0;32m-> 1919\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode(mode)\u001b[38;5;241m.\u001b[39m_jwrite\u001b[38;5;241m.\u001b[39mjdbc(url, table, jprop)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pyspark/errors/exceptions/captured.py:169\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    171\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o860.jdbc.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 2 in stage 55.0 failed 1 times, most recent failure: Lost task 2.0 in stage 55.0 (TID 81) (192.168.42.129 executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO fact_sale (\"payment_id\",\"customer_id\",\"film_id\",\"store_id\",\"payment_date\",\"sale_amount\",\"rental_date\",\"return_date\") VALUES (29145,14,591,2,'2007-04-09 14:38:51.996+08'::timestamp,7.99,'2005-07-09 16:10:25+08'::timestamp,'2005-07-18 17:10:25+08'::timestamp) was aborted: ERROR: duplicate key value violates unique constraint \"fact_sale_2007h1_pkey\"\n  Detail: Key (payment_id, payment_date)=(29145, 2007-04-09 14:38:51.996) already exists.  Call getNextException to see other errors in the batch.\n\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:170)\n\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)\n\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2133)\n\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1490)\n\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1515)\n\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:559)\n\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:905)\n\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:928)\n\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1685)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:746)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)\n\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\nCaused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"fact_sale_2007h1_pkey\"\n  Detail: Key (payment_id, payment_date)=(29145, 2007-04-09 14:38:51.996) already exists.\n\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)\n\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)\n\t... 24 more\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2844)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2780)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2779)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2779)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1242)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1242)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1242)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3048)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2982)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2971)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:984)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2419)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2438)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2463)\n\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$1(RDD.scala:1036)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:407)\n\tat org.apache.spark.rdd.RDD.foreachPartition(RDD.scala:1034)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.saveTable(JdbcUtils.scala:901)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:70)\n\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\n\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n\tat org.apache.spark.sql.DataFrameWriter.jdbc(DataFrameWriter.scala:756)\n\tat jdk.internal.reflect.GeneratedMethodAccessor84.invoke(Unknown Source)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\nCaused by: java.sql.BatchUpdateException: Batch entry 0 INSERT INTO fact_sale (\"payment_id\",\"customer_id\",\"film_id\",\"store_id\",\"payment_date\",\"sale_amount\",\"rental_date\",\"return_date\") VALUES (29145,14,591,2,'2007-04-09 14:38:51.996+08'::timestamp,7.99,'2005-07-09 16:10:25+08'::timestamp,'2005-07-18 17:10:25+08'::timestamp) was aborted: ERROR: duplicate key value violates unique constraint \"fact_sale_2007h1_pkey\"\n  Detail: Key (payment_id, payment_date)=(29145, 2007-04-09 14:38:51.996) already exists.  Call getNextException to see other errors in the batch.\n\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:170)\n\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)\n\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2133)\n\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1490)\n\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1515)\n\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:559)\n\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:905)\n\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:928)\n\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1685)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:746)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:902)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:901)\n\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1036)\n\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1036)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\t... 1 more\nCaused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"fact_sale_2007h1_pkey\"\n  Detail: Key (payment_id, payment_date)=(29145, 2007-04-09 14:38:51.996) already exists.\n\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2712)\n\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2400)\n\t... 24 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/06 19:43:34 INFO BlockManagerInfo: Removed broadcast_74_piece0 on 192.168.42.129:43857 in memory (size: 34.5 KiB, free: 434.4 MiB)\n",
      "23/12/06 19:43:34 INFO BlockManagerInfo: Removed broadcast_73_piece0 on 192.168.42.129:43857 in memory (size: 34.5 KiB, free: 434.4 MiB)\n",
      "23/12/06 19:43:34 INFO BlockManagerInfo: Removed broadcast_75_piece0 on 192.168.42.129:43857 in memory (size: 11.3 KiB, free: 434.4 MiB)\n"
     ]
    }
   ],
   "source": [
    "load_fact_df(fact_sale, 'fact_sale', 4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
